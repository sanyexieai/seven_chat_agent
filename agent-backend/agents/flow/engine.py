from typing import Any, Dict, List, Optional, AsyncGenerator, Callable, Tuple
from utils.log_helper import get_logger
from .base_node import BaseFlowNode, NodeCategory, NodeRegistry
from models.chat_models import AgentMessage, StreamChunk
import uuid
import asyncio

logger = get_logger("flow_engine")


class FlowEngine:
	"""
	å·¥ä½œæµå¼•æ“ï¼šè´Ÿè´£æ„å»ºä¸æ‰§è¡Œç”± BaseFlowNode ç»„æˆçš„èŠ‚ç‚¹æœ‰å‘å›¾
	
	èƒ½åŠ›ï¼š
	- ä» {nodes, edges} é…ç½®æ„å»ºå›¾
	- è‡ªåŠ¨æ£€æµ‹èµ·å§‹èŠ‚ç‚¹ï¼ˆæ˜¾å¼æŒ‡å®šã€STARTç±»åˆ«ã€æˆ–å…¥åº¦ä¸º0ï¼‰
	- é¡ºåºæ‰§è¡ŒèŠ‚ç‚¹ï¼›è·¯ç”±èŠ‚ç‚¹é€šè¿‡å…¶ connections å†³å®šä¸‹ä¸€è·³
	- åŒæ­¥ä¸æµå¼æ‰§è¡Œï¼ˆyield StreamChunkï¼‰
	- æ ‡å‡†åŒ–å‘å‡º node_start/node_complete äº‹ä»¶
	- é€šè¿‡èŠ‚ç‚¹çš„ requires_mount()/get_mount_spec() æš´éœ²æŒ‚è½½å®¹å™¨çš„é’©å­
	
	å¯æ’æ‹”ç‚¹ï¼š
	- mount_provider: Callable[[Dict[str, Any]], Any]
	  è´Ÿè´£æ ¹æ® mount è§„èŒƒå‡†å¤‡å¤–éƒ¨ç¯å¢ƒï¼ˆä¾‹å¦‚ Docker å®¹å™¨ï¼‰ï¼Œè¿”å›å¯é€‰çš„ handler
	- on_chunk: Callable[[StreamChunk], Optional[StreamChunk]]
	  å¤„ç†æ¯ä¸ªæµå¼å—çš„å›è°ƒï¼Œå¯ä»¥ä¿®æ”¹æˆ–è¿‡æ»¤å—
	- on_final: Callable[[StreamChunk], None]
	  å¤„ç†æœ€ç»ˆå“åº”çš„å›è°ƒï¼Œç”¨äºä¿å­˜æ•°æ®ç­‰ä¸šåŠ¡é€»è¾‘
	"""
	
	def __init__(
		self,
		mount_provider: Optional[Callable[[Dict[str, Any]], Any]] = None,
		on_chunk: Optional[Callable[[StreamChunk], Optional[StreamChunk]]] = None,
		on_final: Optional[Callable[[StreamChunk], None]] = None
	):
		self.mount_provider = mount_provider
		self.on_chunk = on_chunk
		self.on_final = on_final
		self._node_map: Dict[str, BaseFlowNode] = {}
		self._adj: Dict[str, List[Optional[str]]] = {}
		self._in_degree: Dict[str, int] = {}
	
	# ========== æ„å»º ==========
	def build_from_config(self, graph_config: Dict[str, Any]) -> "FlowEngine":
		"""
		graph_config:
		{
			"nodes": [ node_config, ... ],
			"edges": [
				{"source": "id1", "target": "id2", "sourceIndex": 0}, ...
			]
		}
		- è‹¥ä¸æä¾› edgesï¼Œåˆ™ä»å„èŠ‚ç‚¹ config/connections ä¸­è¯»å–
		- ç¡®ä¿ç¬¬ä¸€ä¸ªèŠ‚ç‚¹æ˜¯å¼€å§‹èŠ‚ç‚¹ï¼Œæœ€åä¸€ä¸ªèŠ‚ç‚¹æ˜¯ç»“æŸèŠ‚ç‚¹
		"""
		nodes_cfg: List[Dict[str, Any]] = graph_config.get('nodes', [])
		edges_cfg: List[Dict[str, Any]] = graph_config.get('edges', [])
		
		logger.info(f"ğŸ“‹ åŠ è½½æµç¨‹é…ç½®ï¼šnodes={len(nodes_cfg)}, edges={len(edges_cfg)}")
		if edges_cfg:
			logger.info(f"ğŸ“‹ è¾¹é…ç½®è¯¦æƒ…ï¼š{edges_cfg}")
		
		self._node_map.clear()
		self._adj.clear()
		self._in_degree.clear()
		
		# ç¡®ä¿æœ‰å¼€å§‹å’Œç»“æŸèŠ‚ç‚¹
		has_start = False
		has_end = False
		start_node_id = None
		end_node_id = None
		
		# æ£€æŸ¥ç°æœ‰èŠ‚ç‚¹
		for cfg in nodes_cfg:
			node_data = cfg.get('data', {})
			node_type = cfg.get('type', '')
			implementation = cfg.get('implementation', node_type)
			
			# æ£€æŸ¥æ˜¯å¦æ˜¯å¼€å§‹æˆ–ç»“æŸèŠ‚ç‚¹
			if implementation == 'start' or node_data.get('isStartNode'):
				has_start = True
				start_node_id = cfg.get('id')
			if implementation == 'end' or node_data.get('isEndNode'):
				has_end = True
				end_node_id = cfg.get('id')
		
		# å¦‚æœæ²¡æœ‰å¼€å§‹èŠ‚ç‚¹ï¼Œåˆ›å»ºé»˜è®¤çš„å¼€å§‹èŠ‚ç‚¹
		if not has_start and nodes_cfg:
			start_node_id = 'start_node'
			start_cfg = {
				'id': start_node_id,
				'type': 'start',
				'implementation': 'start',
				'data': {
					'label': 'å¼€å§‹',
					'config': {}
				},
				'position': {'x': 0, 'y': 0}
			}
			nodes_cfg.insert(0, start_cfg)
			logger.info(f"è‡ªåŠ¨æ·»åŠ å¼€å§‹èŠ‚ç‚¹: {start_node_id}")
		
		# å¦‚æœæ²¡æœ‰ç»“æŸèŠ‚ç‚¹ï¼Œåˆ›å»ºé»˜è®¤çš„ç»“æŸèŠ‚ç‚¹
		if not has_end and nodes_cfg:
			end_node_id = 'end_node'
			end_cfg = {
				'id': end_node_id,
				'type': 'end',
				'implementation': 'end',
				'data': {
					'label': 'ç»“æŸ',
					'config': {}
				},
				'position': {'x': 0, 'y': 0}
			}
			nodes_cfg.append(end_cfg)
			logger.info(f"è‡ªåŠ¨æ·»åŠ ç»“æŸèŠ‚ç‚¹: {end_node_id}")
			
			# å¦‚æœæ²¡æœ‰è¾¹ï¼Œå°†æœ€åä¸€ä¸ªéç»“æŸèŠ‚ç‚¹è¿æ¥åˆ°ç»“æŸèŠ‚ç‚¹
			if not edges_cfg and len(nodes_cfg) > 1:
				# æ‰¾åˆ°æœ€åä¸€ä¸ªéç»“æŸèŠ‚ç‚¹
				last_non_end = None
				for cfg in reversed(nodes_cfg[:-1]):  # æ’é™¤åˆšæ·»åŠ çš„ç»“æŸèŠ‚ç‚¹
					if cfg.get('id') != end_node_id:
						last_non_end = cfg.get('id')
						break
				if last_non_end:
					edges_cfg.append({
						'source': last_non_end,
						'target': end_node_id
					})
		
		# å®ä¾‹åŒ–èŠ‚ç‚¹
		for cfg in nodes_cfg:
			node = BaseFlowNode.from_config(cfg)
			self._node_map[node.id] = node
			self._adj[node.id] = list(node.connections or [])
			self._in_degree[node.id] = 0
		
		# åº”ç”¨ edgesï¼ˆè¦†ç›–/å¡«å……èŠ‚ç‚¹çš„ connectionsï¼‰
		if edges_cfg:
			for node in self._node_map.values():
				self._adj[node.id] = []
			# å°† edge å†™å…¥ adjacencyï¼ˆæŒ‰ sourceIndex æ”¾ç½®ï¼Œå¦åˆ™ appendï¼‰
			for e in edges_cfg:
				src = e.get('source')
				tgt = e.get('target')
				idx = e.get('sourceIndex')
				if src not in self._node_map or tgt not in self._node_map:
					logger.warning(f"Edge references unknown node: {src} -> {tgt}")
					continue
				if idx is not None:
					# æ‰©å±•é•¿åº¦è‡³ idx+1
					while len(self._adj[src]) <= idx:
						self._adj[src].append(None)
					self._adj[src][idx] = tgt
				else:
					self._adj[src].append(tgt)
		
		# è®¡ç®—å…¥åº¦
		for src, outs in self._adj.items():
			for tgt in outs:
				if tgt:
					self._in_degree[tgt] = self._in_degree.get(tgt, 0) + 1
		
		# å°† connections å†™å›èŠ‚ç‚¹ï¼Œä¿æŒä¸€è‡´
		for node_id, outs in self._adj.items():
			self._node_map[node_id].set_connections(outs)
		
		# æ‰“å°è°ƒè¯•ä¿¡æ¯ï¼šæ˜¾ç¤ºæ‰€æœ‰èŠ‚ç‚¹åŠå…¶è¿æ¥å…³ç³»
		logger.info(f"ğŸ“Š æµç¨‹æ„å»ºå®Œæˆï¼Œå…± {len(self._node_map)} ä¸ªèŠ‚ç‚¹")
		for node_id, node in self._node_map.items():
			connections = self._adj.get(node_id, [])
			logger.info(f"  - èŠ‚ç‚¹ {node_id} ({node.name}, {node.category.value if hasattr(node.category, 'value') else node.category}, {node.implementation}): è¿æ¥ -> {connections}")
		
		return self
	
	def get_start_node_id(self, explicit_start: Optional[str] = None) -> Optional[str]:
		"""è·å–å¼€å§‹èŠ‚ç‚¹IDï¼Œç¡®ä¿è¿”å›çš„æ˜¯å¼€å§‹èŠ‚ç‚¹"""
		if explicit_start and explicit_start in self._node_map:
			return explicit_start
		# ä¼˜å…ˆï¼šç±»åˆ«ä¸º START
		for node in self._node_map.values():
			if node.category == NodeCategory.START:
				return node.id
		# å…¶æ¬¡ï¼šimplementation ä¸º 'start' çš„èŠ‚ç‚¹
		for node in self._node_map.values():
			if node.implementation == 'start':
				return node.id
		# å†æ¬¡ï¼šå…¥åº¦ä¸º 0 çš„èŠ‚ç‚¹
		candidates = [nid for nid, deg in self._in_degree.items() if deg == 0]
		return candidates[0] if candidates else (next(iter(self._node_map.keys())) if self._node_map else None)
	
	def get_end_node_id(self) -> Optional[str]:
		"""è·å–ç»“æŸèŠ‚ç‚¹ID"""
		# ä¼˜å…ˆï¼šç±»åˆ«ä¸º END
		for node in self._node_map.values():
			if node.category == NodeCategory.END:
				return node.id
		# å…¶æ¬¡ï¼šimplementation ä¸º 'end' çš„èŠ‚ç‚¹
		for node in self._node_map.values():
			if node.implementation == 'end':
				return node.id
		# å†æ¬¡ï¼šå‡ºåº¦ä¸º 0 çš„èŠ‚ç‚¹
		candidates = [nid for nid in self._node_map.keys() if not self._adj.get(nid) or all(not tgt for tgt in self._adj.get(nid, []))]
		return candidates[0] if candidates else None
	
	# ========== æ‰§è¡Œï¼ˆåŒæ­¥ï¼‰ ==========
	async def run(
		self,
		user_id: str,
		message: str,
		context: Optional[Dict[str, Any]],
		start_node_id: Optional[str] = None,
		agent_name: Optional[str] = None
	) -> List[AgentMessage]:
		context = context or {}
		
		# åˆå§‹åŒ– Pipelineï¼ˆå¦‚æœå°šæœªåˆå§‹åŒ–ï¼‰
		from .pipeline import get_pipeline
		pipeline = get_pipeline(context)
		pipeline.sync_to_flow_state(context)
		
		results: List[AgentMessage] = []
		
		current_id = self.get_start_node_id(start_node_id)
		if not current_id:
			logger.warning("No start node found.")
			return results
		
		while current_id:
			node = self._node_map.get(current_id)
			if not node:
				logger.warning(f"Node not found: {current_id}")
				break
			
			mount_handler = None
			if node.requires_mount() and self.mount_provider:
				try:
					mount_handler = self.mount_provider(node.get_mount_spec() or {})
				except Exception as e:
					logger.error(f"Mount provider failed for node {node.id}: {e}")
			
			msg = await node.execute(user_id=user_id, message=message, context=context, agent_name=agent_name)
			if msg:
				results.append(msg)
				# è‹¥èŠ‚ç‚¹æœªè‡ªè¡Œä¿å­˜ï¼Œå°è¯•ç”¨æ¶ˆæ¯å†…å®¹ä¿å­˜æ ‡å‡†è¾“å‡º
				try:
					if hasattr(node, "save_output") and msg.content is not None:
						node.save_output(context, msg.content)
				except Exception:
					pass
			
			# é€‰æ‹©ä¸‹ä¸€è·³
			# è·¯ç”±èŠ‚ç‚¹éœ€è¦æ ¹æ®é€‰ä¸­çš„åˆ†æ”¯é€‰æ‹©
			if node.category == NodeCategory.ROUTER:
				# ä»èŠ‚ç‚¹æ•°æ®ä¸­è·å–é€‰ä¸­çš„åˆ†æ”¯
				selected_branch = node.get_node_value(context, 'selected_branch', node_id=node.id)
				if selected_branch == 'true' and len(node.connections) > 0:
					next_id = node.connections[0]  # ç¬¬ä¸€ä¸ªåˆ†æ”¯ï¼šçœŸå€¼åˆ†æ”¯
				elif selected_branch == 'false' and len(node.connections) > 1:
					next_id = node.connections[1]  # ç¬¬äºŒä¸ªåˆ†æ”¯ï¼šå‡å€¼åˆ†æ”¯
				elif len(node.connections) > 0:
					next_id = node.connections[0]  # åªæœ‰ä¸€ä¸ªåˆ†æ”¯ï¼Œç»§ç»­æ‰§è¡Œ
				else:
					next_id = None
			else:
				next_id = node.get_next_node_id(0)  # ç¼ºçœèµ°ç¬¬ä¸€ä¸ªåˆ†æ”¯
			
			if node.category == NodeCategory.END:
				next_id = None
			
			current_id = next_id
		
		return results
	
	# ========== æ‰§è¡Œï¼ˆæµå¼ï¼‰ ==========
	async def run_stream(
		self,
		user_id: str,
		message: str,
		context: Optional[Dict[str, Any]],
		start_node_id: Optional[str] = None,
		agent_name: Optional[str] = None,
		session_id: Optional[str] = None
	) -> AsyncGenerator[StreamChunk, None]:
		context = context or {}
		session_id = session_id or str(uuid.uuid4())
		
		current_id = self.get_start_node_id(start_node_id)
		if not current_id:
			logger.warning("No start node found.")
			error_chunk = StreamChunk(
				chunk_id=str(uuid.uuid4()),
				session_id=session_id,
				type="error",
				content="å·¥ä½œæµæœªæ‰¾åˆ°èµ·å§‹èŠ‚ç‚¹",
				agent_name=agent_name or "FlowEngine",
				is_end=True
			)
			if self.on_chunk:
				error_chunk = self.on_chunk(error_chunk) or error_chunk
			if error_chunk:
				yield error_chunk
			return
		
		logger.info(f"FlowEngine.run_stream å¼€å§‹æ‰§è¡Œï¼Œstart_node_id={current_id}, session_id={session_id}, on_final={self.on_final is not None}")
		final_chunk = None
		
		while current_id:
			node = self._node_map.get(current_id)
			if not node:
				logger.warning(f"Node not found: {current_id}")
				break
			
			# å‘é€èŠ‚ç‚¹å¼€å§‹äº‹ä»¶
			# _create_stream_chunk ä¼šè‡ªåŠ¨æ·»åŠ  node_id, node_category, node_implementation, node_name, node_label åˆ° metadata
			node_start_chunk = node._create_stream_chunk(
				chunk_type="node_start",
				content=node.name,
				session_id=session_id,
				agent_name=agent_name,
				metadata={}  # åŸºç¡€ä¿¡æ¯ç”± _create_stream_chunk è‡ªåŠ¨æ·»åŠ 
			)
			if self.on_chunk:
				node_start_chunk = self.on_chunk(node_start_chunk)
			if node_start_chunk:
				yield node_start_chunk
			
			mount_handler = None
			if node.requires_mount() and self.mount_provider:
				try:
					mount_handler = self.mount_provider(node.get_mount_spec() or {})
				except Exception as e:
					logger.error(f"Mount provider failed for node {node.id}: {e}")
			
			# æ‰§è¡ŒèŠ‚ç‚¹æµ
			# æ”¶é›†å½“å‰èŠ‚ç‚¹çš„è¾“å‡ºå†…å®¹ï¼ˆä» content chunk ä¸­æ”¶é›†ï¼‰
			# æ³¨æ„ï¼šåªæ”¶é›†å±äºå½“å‰èŠ‚ç‚¹çš„ content chunkï¼Œä¸æ”¶é›†å…¶ä»–ç±»å‹çš„ chunk
			node_output_content = ""
			current_node_final_chunk = None  # å½“å‰èŠ‚ç‚¹çš„ final chunkï¼ˆå¦‚æœæœ‰ï¼‰
			async for chunk in node.execute_stream(user_id=user_id, message=message, context=context, agent_name=agent_name):
				# æ”¶é›† content ç±»å‹çš„ chunk å†…å®¹
				if chunk.type == "content" and chunk.content is not None:
					# ç´¯åŠ èŠ‚ç‚¹çš„è¾“å‡ºå†…å®¹
					# æ³¨æ„ï¼šå¯¹äºæµå¼è¾“å‡ºï¼Œæ¯ä¸ª chunk æ˜¯å¢é‡å†…å®¹ï¼Œç›´æ¥ç´¯åŠ å³å¯
					chunk_content = chunk.content if isinstance(chunk.content, str) else str(chunk.content)
					node_output_content += chunk_content
					logger.debug(f"èŠ‚ç‚¹ {node.id} ç´¯åŠ  content chunkï¼Œå½“å‰ node_output_content length={len(node_output_content)}")
					# è‹¥ä¸ºå†…å®¹æµï¼Œå°è¯•å¢é‡ä¿å­˜ last_output
					try:
						if hasattr(node, "save_output"):
							node.save_output(context, chunk_content)
					except Exception:
						pass
				# å¯¹äº tool_result ç±»å‹ï¼Œä¹Ÿæ”¶é›†å†…å®¹ï¼ˆå·¥å…·èŠ‚ç‚¹ä¼šåŒæ—¶å‘é€ tool_result å’Œ contentï¼‰
				elif chunk.type == "tool_result" and chunk.content is not None:
					# å·¥å…·ç»“æœå·²ç»é€šè¿‡ content chunk å‘é€ï¼Œè¿™é‡Œä¸éœ€è¦é‡å¤æ”¶é›†
					pass
				
				# å¦‚æœæ˜¯æœ€ç»ˆå—ï¼Œåœ¨è°ƒç”¨é’©å­ä¹‹å‰å…ˆä¿å­˜å¼•ç”¨ï¼ˆé¿å…é’©å­ä¿®æ”¹æˆ–è¿‡æ»¤ï¼‰
				if chunk and chunk.type == "final":
					final_chunk_content = chunk.content if isinstance(chunk.content, str) else str(chunk.content) if chunk.content else ""
					logger.info(f"èŠ‚ç‚¹ {node.id} å‘é€äº† final chunkï¼Œä¿å­˜å¼•ç”¨ï¼Œcontent type={type(chunk.content)}, content length={len(final_chunk_content)}, node_output_content length={len(node_output_content)}, content preview={repr(final_chunk_content[:200]) if final_chunk_content else 'None'}")
					final_chunk = chunk
					current_node_final_chunk = chunk  # ä¿å­˜å½“å‰èŠ‚ç‚¹çš„ final chunk
					
					# å¯¹äº LLM èŠ‚ç‚¹ï¼Œfinal chunk åŒ…å«å®Œæ•´çš„è¾“å‡ºå†…å®¹
					# ä¼˜å…ˆä½¿ç”¨ final chunk çš„å†…å®¹ï¼ˆå®ƒåŒ…å«å®Œæ•´çš„è¾“å‡ºï¼‰ï¼Œå› ä¸ºå®ƒå¯èƒ½æ¯”ç´¯åŠ çš„ node_output_content æ›´å®Œæ•´
					if final_chunk_content:
						# å¦‚æœ final chunk çš„å†…å®¹æ›´é•¿æˆ– node_output_content ä¸ºç©ºï¼Œä½¿ç”¨ final chunk çš„å†…å®¹
						if len(final_chunk_content) >= len(node_output_content):
							node_output_content = final_chunk_content
							logger.info(f"èŠ‚ç‚¹ {node.id} ä½¿ç”¨ final chunk çš„å†…å®¹æ›´æ–° node_output_contentï¼Œlength={len(node_output_content)}")
						else:
							logger.warning(f"èŠ‚ç‚¹ {node.id} final chunk çš„å†…å®¹æ¯” node_output_content çŸ­ï¼Œfinal_chunk length={len(final_chunk_content)}, node_output_content length={len(node_output_content)}")
					
					# æ³¨æ„ï¼šä¸è¦åœ¨è¿™é‡Œè°ƒç”¨ on_final é’©å­ï¼Œå› ä¸ºæµç¨‹å¯èƒ½è¿˜æ²¡æœ‰æ‰§è¡Œåˆ°ç»“æŸèŠ‚ç‚¹
					# on_final é’©å­åº”è¯¥åœ¨æ‰€æœ‰èŠ‚ç‚¹æ‰§è¡Œå®Œæˆåè°ƒç”¨ï¼ˆåœ¨ while å¾ªç¯ç»“æŸåï¼‰
					# ä½†æ˜¯ï¼Œç”±äº api/chat.py åœ¨æ”¶åˆ° final chunk åä¼š breakï¼Œæˆ‘ä»¬éœ€è¦å»¶è¿Ÿè°ƒç”¨ on_final
					# æš‚æ—¶ä¸è°ƒç”¨ï¼Œè®©æµç¨‹ç»§ç»­æ‰§è¡Œåˆ°ç»“æŸèŠ‚ç‚¹
					# ä½†æ˜¯ï¼Œæˆ‘ä»¬éœ€è¦ç¡®ä¿æ¶ˆæ¯è¢«ä¿å­˜ï¼Œæ‰€ä»¥å¦‚æœè¿™æ˜¯ç¬¬ä¸€ä¸ª final chunkï¼Œå…ˆä¿å­˜æ¶ˆæ¯
					# ä½†ä¸è¦ breakï¼Œè®©æµç¨‹ç»§ç»­æ‰§è¡Œåˆ°ç»“æŸèŠ‚ç‚¹
				
				# è°ƒç”¨é’©å­å¤„ç†å—
				if self.on_chunk:
					chunk = self.on_chunk(chunk)
					# å¦‚æœé’©å­è¿”å› Noneï¼Œè¯´æ˜è¢«è¿‡æ»¤äº†ï¼Œä½†æˆ‘ä»¬å·²ç»ä¿å­˜äº† final_chunk çš„å¼•ç”¨
				
				# é€ä¼ èŠ‚ç‚¹æµ
				if chunk:
					yield chunk
			
			# èŠ‚ç‚¹æ‰§è¡Œå®Œæˆåï¼Œä¼˜å…ˆä½¿ç”¨æ”¶é›†åˆ°çš„å†…å®¹
			# å¦‚æœæ²¡æœ‰æ”¶é›†åˆ°å†…å®¹ï¼Œå°è¯•ä»èŠ‚ç‚¹çš„ outputs åˆ—è¡¨ä¸­è·å–æœ€åè¾“å‡º
			if not node_output_content:
				try:
					node_outputs = node.get_node_outputs(context, node.id)
					if node_outputs:
						# è·å–æœ€åä¸€ä¸ªè¾“å‡ºï¼ˆé€šå¸¸æ˜¯å®Œæ•´çš„ç´¯ç§¯è¾“å‡ºï¼‰
						# æ³¨æ„ï¼šLLM èŠ‚ç‚¹ä¼šå¤šæ¬¡è°ƒç”¨ save_outputï¼Œæ¯æ¬¡ä¿å­˜ç´¯ç§¯å†…å®¹
						# æ‰€ä»¥æœ€åä¸€ä¸ªè¾“å‡ºæ˜¯å®Œæ•´çš„è¾“å‡º
						last_output = node_outputs[-1]
						if isinstance(last_output, str):
							node_output_content = last_output
						else:
							node_output_content = str(last_output)
				except Exception:
					pass
			
			# å¦‚æœè¿˜æ˜¯æ²¡æœ‰ï¼Œå°è¯•ä»èŠ‚ç‚¹çš„æœ€åè¾“å‡ºè·å–ï¼ˆè¿™ä¸ªæ–¹æ³•ä¼šè°ƒç”¨ get_node_outputsï¼‰
			if not node_output_content:
				try:
					last_output = node.get_last_output_of_node(context, node.id)
					if last_output:
						if isinstance(last_output, str):
							node_output_content = last_output
						else:
							node_output_content = str(last_output)
				except Exception:
					pass
			
			# å¦‚æœè¿˜æ˜¯æ²¡æœ‰ï¼Œæ ¹æ®èŠ‚ç‚¹ç±»å‹å†³å®š
			if not node_output_content:
				if node.category.value == 'start':
					# start èŠ‚ç‚¹é€šå¸¸æ²¡æœ‰è¾“å‡ºå†…å®¹
					node_output_content = ""
				elif node.category.value == 'end':
					# end èŠ‚ç‚¹å¦‚æœæ²¡æœ‰è¾“å‡ºå†…å®¹ï¼Œä½¿ç”¨é»˜è®¤çš„"ç»“æŸ"
					node_output_content = "ç»“æŸ"
				elif node.category.value == 'router':
					# è·¯ç”±èŠ‚ç‚¹ï¼šå°è¯•ä»è·¯ç”±å†³ç­–ä¸­è·å–
					try:
						router_decision = context.get('flow_state', {}).get('router_decision', {})
						if router_decision:
							field = router_decision.get('field', '')
							value = router_decision.get('value', '')
							selected_branch = router_decision.get('selected_branch', '')
							node_output_content = f"è·¯ç”±å†³ç­–: {field}={value} -> {selected_branch}"
					except Exception:
						pass
				else:
					# å…¶ä»–èŠ‚ç‚¹ç±»å‹ï¼Œä¸ä½¿ç”¨å…¨å±€ last_outputï¼ˆé¿å…æ˜¾ç¤ºé”™è¯¯çš„å†…å®¹ï¼‰
					# å¦‚æœç¡®å®æ²¡æœ‰è¾“å‡ºï¼Œå°±æ˜¾ç¤ºç©ºå­—ç¬¦ä¸²
					node_output_content = ""
			
			# å‘é€èŠ‚ç‚¹å®Œæˆäº‹ä»¶
			# _create_stream_chunk ä¼šè‡ªåŠ¨æ·»åŠ  node_id, node_category, node_implementation, node_name, node_label åˆ° metadata
			# å¯¹äº LLM èŠ‚ç‚¹ï¼Œå¦‚æœå‘é€äº† final chunkï¼Œåº”è¯¥ä½¿ç”¨ final chunk çš„å†…å®¹ä½œä¸ºèŠ‚ç‚¹è¾“å‡º
			# å¦åˆ™ä½¿ç”¨æ”¶é›†åˆ°çš„ node_output_content
			final_output = node_output_content
			if current_node_final_chunk and current_node_final_chunk.content:
				# å¦‚æœå½“å‰èŠ‚ç‚¹å‘é€äº† final chunkï¼Œä¼˜å…ˆä½¿ç”¨ final chunk çš„å†…å®¹ï¼ˆå®ƒåŒ…å«å®Œæ•´çš„è¾“å‡ºï¼‰
				# ä½†æ˜¯ï¼Œå¦‚æœ node_output_content æ›´é•¿ï¼Œè¯´æ˜å®ƒå·²ç»åŒ…å«äº†æ‰€æœ‰å†…å®¹ï¼Œä½¿ç”¨å®ƒ
				final_chunk_content = current_node_final_chunk.content if isinstance(current_node_final_chunk.content, str) else str(current_node_final_chunk.content)
				if len(final_chunk_content) > len(node_output_content):
					final_output = final_chunk_content
					logger.info(f"ğŸ“ èŠ‚ç‚¹ {node.id} ({node.name}) ä½¿ç”¨ final chunk çš„å†…å®¹ä½œä¸ºè¾“å‡ºï¼Œlength={len(final_output)}, preview={repr(final_output[:100])}")
				else:
					# node_output_content å·²ç»åŒ…å«äº†å®Œæ•´å†…å®¹ï¼Œä½¿ç”¨å®ƒ
					final_output = node_output_content
					logger.info(f"ğŸ“ èŠ‚ç‚¹ {node.id} ({node.name}) ä½¿ç”¨æ”¶é›†åˆ°çš„ node_output_contentï¼ˆæ¯” final chunk æ›´é•¿ï¼‰ï¼Œlength={len(final_output)}, preview={repr(final_output[:100])}")
			elif node_output_content:
				logger.info(f"ğŸ“ èŠ‚ç‚¹ {node.id} ({node.name}) ä½¿ç”¨æ”¶é›†åˆ°çš„ node_output_contentï¼Œlength={len(node_output_content)}, preview={repr(node_output_content[:100])}")
			else:
				logger.warning(f"âš ï¸ èŠ‚ç‚¹ {node.id} ({node.name}) æ²¡æœ‰è¾“å‡ºå†…å®¹")
			
			node_complete_chunk = node._create_stream_chunk(
				chunk_type="node_complete",
				content=node.name,
				session_id=session_id,
				agent_name=agent_name,
				metadata={"output": final_output}  # ä½¿ç”¨å½“å‰èŠ‚ç‚¹çš„è¾“å‡ºï¼Œè€Œä¸æ˜¯å…¨å±€çš„ last_output
			)
			logger.info(f"ğŸ“¤ å‘é€èŠ‚ç‚¹å®Œæˆäº‹ä»¶ï¼šnode_id={node.id}, output length={len(final_output) if final_output else 0}")
			if self.on_chunk:
				node_complete_chunk = self.on_chunk(node_complete_chunk)
			if node_complete_chunk:
				yield node_complete_chunk
			
			# é€‰æ‹©ä¸‹ä¸€è·³
			# è·¯ç”±èŠ‚ç‚¹éœ€è¦æ ¹æ®é€‰ä¸­çš„åˆ†æ”¯é€‰æ‹©
			if node.category == NodeCategory.ROUTER:
				# ä»èŠ‚ç‚¹æ•°æ®ä¸­è·å–é€‰ä¸­çš„åˆ†æ”¯
				selected_branch = node.get_node_value(context, 'selected_branch', node_id=node.id)
				if selected_branch == 'true' and len(node.connections) > 0:
					next_id = node.connections[0]  # ç¬¬ä¸€ä¸ªåˆ†æ”¯ï¼šçœŸå€¼åˆ†æ”¯
				elif selected_branch == 'false' and len(node.connections) > 1:
					next_id = node.connections[1]  # ç¬¬äºŒä¸ªåˆ†æ”¯ï¼šå‡å€¼åˆ†æ”¯
				elif len(node.connections) > 0:
					next_id = node.connections[0]  # åªæœ‰ä¸€ä¸ªåˆ†æ”¯ï¼Œç»§ç»­æ‰§è¡Œ
				else:
					next_id = None
			else:
				next_id = node.get_next_node_id(0)
			
			if node.category == NodeCategory.END:
				next_id = None
			
			logger.info(f"ğŸ”„ èŠ‚ç‚¹ {node.id} ({node.name}) æ‰§è¡Œå®Œæˆï¼Œä¸‹ä¸€ä¸ªèŠ‚ç‚¹: {next_id}, å½“å‰è¿æ¥åˆ—è¡¨: {node.connections}")
			current_id = next_id
		
		# whileå¾ªç¯ç»“æŸåï¼Œå¤„ç†æœ€ç»ˆå—å’Œé’©å­
		logger.info(f"whileå¾ªç¯ç»“æŸï¼Œcurrent_id={current_id}, final_chunk={final_chunk is not None}")
		
		# å¦‚æœæ²¡æœ‰æœ€ç»ˆå—ï¼Œåˆ›å»ºä¸€ä¸ª
		if not final_chunk:
			final_content = context.get('flow_state', {}).get('last_output', '')
			logger.info(f"æœªæ‰¾åˆ° final chunkï¼Œåˆ›å»ºæ–°çš„ final chunkï¼Œcontent length={len(final_content) if final_content else 0}")
			# åœ¨æœ€ç»ˆå“åº”ä¸­åŒ…å« flow_stateï¼ˆåŒ…å« pipeline æ•°æ®ï¼‰
			flow_state = context.get('flow_state', {})
			final_chunk = StreamChunk(
				chunk_id=str(uuid.uuid4()),
				session_id=session_id,
				type="final",
				content=final_content,
				agent_name=agent_name or "FlowEngine",
				metadata={
					'flow_state': flow_state  # åŒ…å« pipeline_data, pipeline_files, pipeline_history
				},
				is_end=True
			)
		else:
			logger.info(f"æ‰¾åˆ° final chunkï¼Œtype={final_chunk.type}, content length={len(final_chunk.content) if final_chunk.content else 0}")
		
		# è°ƒç”¨æœ€ç»ˆé’©å­ï¼ˆåœ¨yieldä¹‹å‰è°ƒç”¨ï¼Œç¡®ä¿æ¶ˆæ¯è¢«ä¿å­˜ï¼‰
		# æ³¨æ„ï¼šå¦‚æœ final chunk å·²ç»åœ¨ while å¾ªç¯ä¸­è¢«å¤„ç†ï¼Œon_final å·²ç»åœ¨é‚£ä¸ªæ—¶å€™è¢«è°ƒç”¨äº†
		# ä½†æ˜¯ï¼Œæ­¤æ—¶æ‰€æœ‰èŠ‚ç‚¹åº”è¯¥éƒ½å·²ç»å®Œæˆäº†ï¼Œæ‰€ä»¥éœ€è¦å†æ¬¡ä¿å­˜èŠ‚ç‚¹ä¿¡æ¯ä»¥ç¡®ä¿æ‰€æœ‰èŠ‚ç‚¹è¾“å‡ºéƒ½è¢«ä¿å­˜
		if self.on_final:
			if not final_chunk:
				# å¦‚æœæ²¡æœ‰ final chunkï¼Œåˆ›å»ºä¸€ä¸ªå¹¶è°ƒç”¨ on_final
				try:
					logger.info(f"whileå¾ªç¯ç»“æŸåæ²¡æœ‰ final chunkï¼Œåˆ›å»ºæ–°çš„å¹¶è°ƒç”¨ on_final é’©å­")
					self.on_final(final_chunk)
					logger.info("on_final é’©å­æ‰§è¡Œå®Œæˆ")
				except Exception as e:
					logger.error(f"Final hook failed: {e}", exc_info=True)
			else:
				# æ­¤æ—¶æ‰€æœ‰èŠ‚ç‚¹åº”è¯¥éƒ½å·²ç»å®Œæˆäº†ï¼ŒåŒ…æ‹¬ç»“æŸèŠ‚ç‚¹
				# è°ƒç”¨ on_final é’©å­ä¿å­˜æ¶ˆæ¯å’ŒèŠ‚ç‚¹ä¿¡æ¯
				try:
					logger.info(f"whileå¾ªç¯ç»“æŸåè°ƒç”¨ on_final é’©å­ï¼Œfinal_chunk type={final_chunk.type}, content length={len(final_chunk.content) if final_chunk.content else 0}")
					self.on_final(final_chunk)
					logger.info("on_final é’©å­æ‰§è¡Œå®Œæˆ")
				except Exception as e:
					logger.error(f"Final hook failed: {e}", exc_info=True)
		else:
			logger.warning("on_final é’©å­æœªè®¾ç½®ï¼Œæ— æ³•ä¿å­˜åŠ©æ‰‹æ¶ˆæ¯")
		
		# å‘é€æœ€ç»ˆå—ï¼ˆåœ¨on_finalä¹‹åå‘é€ï¼Œç¡®ä¿æ¶ˆæ¯å·²ä¿å­˜ï¼‰
		# ç¡®ä¿ final_chunk åŒ…å« flow_stateï¼ˆå¦‚æœè¿˜æ²¡æœ‰ï¼‰
		if final_chunk and not final_chunk.metadata.get('flow_state'):
			flow_state = context.get('flow_state', {})
			if final_chunk.metadata:
				final_chunk.metadata['flow_state'] = flow_state
			else:
				final_chunk.metadata = {'flow_state': flow_state}
		
		if self.on_chunk:
			final_chunk = self.on_chunk(final_chunk) or final_chunk
		if final_chunk:
			logger.info(f"yield final chunkï¼Œtype={final_chunk.type}, content length={len(final_chunk.content) if final_chunk.content else 0}")
			yield final_chunk
		
		logger.info("FlowEngine.run_stream æ‰§è¡Œå®Œæˆ")


