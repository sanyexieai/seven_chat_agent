from typing import Dict, Any, AsyncGenerator
from agents.base_agent import BaseAgent
from models.chat_models import AgentMessage, StreamChunk, MessageType, AgentContext
from utils.log_helper import get_logger
from utils.llm_helper import get_llm_helper
import asyncio
import json
import uuid
from typing import List

logger = get_logger("general_agent")

class GeneralAgent(BaseAgent):
    """é€šç”¨æ™ºèƒ½ä½“
    
    é€šè¿‡æ•°æ®åº“é…ç½®çš„ç³»ç»Ÿæç¤ºè¯æ¥å®ç°ä¸åŒçš„åŠŸèƒ½ã€‚
    è¿™ç§æ™ºèƒ½ä½“å®Œå…¨ä¾èµ–æç¤ºè¯æ¥å®šä¹‰è¡Œä¸ºï¼Œæ”¯æŒå·¥å…·è°ƒç”¨å’ŒçŸ¥è¯†åº“æŸ¥è¯¢ã€‚
    """
    
    def __init__(self, name: str, description: str, system_prompt: str = None, llm_config: Dict[str, Any] = None):
        super().__init__(name, description)
        
        # é»˜è®¤ç³»ç»Ÿæç¤ºè¯
        self.default_system_prompt = """ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½AIåŠ©æ‰‹ï¼Œèƒ½å¤Ÿå¸®åŠ©ç”¨æˆ·è§£ç­”é—®é¢˜ã€è¿›è¡Œå¯¹è¯äº¤æµã€‚
è¯·ç”¨ç®€æ´ã€å‡†ç¡®ã€å‹å¥½çš„æ–¹å¼å›åº”ç”¨æˆ·çš„é—®é¢˜ã€‚ä¿æŒå¯¹è¯çš„è‡ªç„¶æ€§å’Œè¿è´¯æ€§ã€‚"""
        
        # ä½¿ç”¨ä¼ å…¥çš„ç³»ç»Ÿæç¤ºè¯æˆ–é»˜è®¤æç¤ºè¯
        self.system_prompt = system_prompt or self.default_system_prompt
        
        # ä¿å­˜LLMé…ç½®
        self.llm_config = llm_config
        
        # çŸ¥è¯†åº“é…ç½®
        self.bound_knowledge_bases = []
        
        # ç»‘å®šå·¥å…·é…ç½®
        self.bound_tools = []
        
        # åˆå§‹åŒ–LLMåŠ©æ‰‹
        try:
            if llm_config:
                # ä½¿ç”¨æ™ºèƒ½ä½“ç‰¹å®šçš„LLMé…ç½®
                self.llm_helper = get_llm_helper(llm_config)
                logger.info(f"é€šç”¨æ™ºèƒ½ä½“ {name} ä½¿ç”¨ç‰¹å®šLLMé…ç½®åˆå§‹åŒ–æˆåŠŸ")
            else:
                # ä½¿ç”¨é»˜è®¤LLMé…ç½®
                self.llm_helper = get_llm_helper()
                logger.info(f"é€šç”¨æ™ºèƒ½ä½“ {name} ä½¿ç”¨é»˜è®¤LLMé…ç½®åˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            logger.error(f"LLMåˆå§‹åŒ–å¤±è´¥: {str(e)}")
            raise
    
    def set_system_prompt(self, prompt: str):
        """è®¾ç½®ç³»ç»Ÿæç¤ºè¯"""
        self.system_prompt = prompt
        logger.info(f"æ™ºèƒ½ä½“ {self.name} ç³»ç»Ÿæç¤ºè¯å·²æ›´æ–°")
    
    def get_system_prompt(self) -> str:
        """è·å–ç³»ç»Ÿæç¤ºè¯"""
        return self.system_prompt
    
    def set_knowledge_bases(self, knowledge_bases: List[Dict[str, Any]]):
        """è®¾ç½®ç»‘å®šçš„çŸ¥è¯†åº“"""
        self.bound_knowledge_bases = knowledge_bases
        logger.info(f"æ™ºèƒ½ä½“ {self.name} ç»‘å®šçŸ¥è¯†åº“: {[kb.get('name', 'Unknown') for kb in knowledge_bases]}")
    
    def set_bound_tools(self, tools: List[Any]):
        """è®¾ç½®ç»‘å®šçš„å·¥å…·"""
        self.bound_tools = tools
        logger.info(f"æ™ºèƒ½ä½“ {self.name} ç»‘å®šå·¥å…·: {len(tools)} ä¸ª")
    
    async def query_knowledge_base(self, query: str, db_session=None) -> str:
        """æŸ¥è¯¢çŸ¥è¯†åº“"""
        if not self.bound_knowledge_bases:
            return ""
        
        try:
            from services.knowledge_base_service import KnowledgeBaseService
            kb_service = KnowledgeBaseService()
            
            all_results = []
            for kb_info in self.bound_knowledge_bases:
                kb_id = kb_info.get('id') or kb_info.get('knowledge_base_id')
                if not kb_id:
                    continue
                
                try:
                    # æŸ¥è¯¢çŸ¥è¯†åº“
                    results = kb_service.query_knowledge_base(db_session, kb_id, query, limit=3)
                    if results and results.get('chunks'):
                        kb_name = kb_info.get('name', f'çŸ¥è¯†åº“{kb_id}')
                        kb_results = f"\n\næ¥è‡ªçŸ¥è¯†åº“ '{kb_name}' çš„ç›¸å…³ä¿¡æ¯ï¼š\n"
                        for chunk in results['chunks']:
                            kb_results += f"- {chunk.get('content', '')}\n"
                        all_results.append(kb_results)
                except Exception as e:
                    logger.warning(f"æŸ¥è¯¢çŸ¥è¯†åº“ {kb_id} å¤±è´¥: {str(e)}")
                    continue
            
            return "\n".join(all_results) if all_results else ""
            
        except Exception as e:
            logger.error(f"çŸ¥è¯†åº“æŸ¥è¯¢å¤±è´¥: {str(e)}")
            return ""
    
    def _build_enhanced_system_prompt(self, knowledge_context: str = "") -> str:
        """æ„å»ºå¢å¼ºçš„ç³»ç»Ÿæç¤ºè¯"""
        enhanced_prompt = self.system_prompt
        
        # æ·»åŠ çŸ¥è¯†åº“ä¿¡æ¯
        if knowledge_context:
            enhanced_prompt += f"\n\nä»¥ä¸‹æ˜¯ç›¸å…³çš„çŸ¥è¯†åº“ä¿¡æ¯ï¼Œè¯·åŸºäºè¿™äº›ä¿¡æ¯å›ç­”ç”¨æˆ·é—®é¢˜ï¼š\n{knowledge_context}"
            enhanced_prompt += "\n\nè¯·ç»“åˆçŸ¥è¯†åº“ä¿¡æ¯ï¼Œæä¾›å‡†ç¡®ã€è¯¦ç»†çš„å›ç­”ã€‚å¦‚æœçŸ¥è¯†åº“ä¿¡æ¯ä¸è¶³ä»¥å›ç­”é—®é¢˜ï¼Œè¯·è¯´æ˜å¹¶æä¾›ä¸€èˆ¬æ€§å»ºè®®ã€‚"
        
        # æ·»åŠ å·¥å…·ä¿¡æ¯
        if self.bound_tools:
            tools_description = "\n\nä½ å¯ä»¥ä½¿ç”¨ä»¥ä¸‹å·¥å…·ï¼š\n"
            for t in self.bound_tools:
                if isinstance(t, str):
                    tools_description += f"- {t}\n"
                elif isinstance(t, dict):
                    server = t.get('server_name') or t.get('server')
                    name = t.get('name') or t.get('tool_name')
                    if server and name:
                        tools_description += f"- {server}_{name}\n"
            
            tools_description += "\n\nå½“éœ€è¦ä½¿ç”¨å·¥å…·æ—¶ï¼Œè¯·ä½¿ç”¨ä»¥ä¸‹æ ¼å¼ï¼š\n"
            tools_description += "TOOL_CALL: <å·¥å…·åç§°> <å‚æ•°>\n"
            tools_description += "ä¾‹å¦‚ï¼šTOOL_CALL: ddg_search query=å•†æ±¤ç§‘æŠ€\n"
            tools_description += "æˆ‘ä¼šè‡ªåŠ¨æ‰§è¡Œå·¥å…·è°ƒç”¨å¹¶è¿”å›ç»“æœã€‚"
            
            enhanced_prompt += tools_description
            logger.info(f"æ™ºèƒ½ä½“ {self.name} çš„ç³»ç»Ÿæç¤ºè¯å·²å¢å¼ºï¼ŒåŒ…å« {len(self.bound_tools)} ä¸ªå·¥å…·")
        
        return enhanced_prompt
    
    def _parse_tool_calls(self, response: str) -> List[str]:
        """è§£æå“åº”ä¸­çš„å·¥å…·è°ƒç”¨æŒ‡ä»¤"""
        tool_calls = []
        lines = response.split('\n')
        
        for line in lines:
            if line.strip().startswith('TOOL_CALL:'):
                tool_call = line.strip().replace('TOOL_CALL:', '').strip()
                tool_calls.append(tool_call)
                logger.info(f"âœ… æ‰¾åˆ°å·¥å…·è°ƒç”¨: '{tool_call}'")
        
        return tool_calls
    
    def _build_tool_mapping(self) -> tuple[set, Dict[str, str]]:
        """æ„å»ºå·¥å…·æ˜ å°„å…³ç³»"""
        bound_tool_keys = set()
        tool_to_server: Dict[str, str] = {}
        
        for t in self.bound_tools:
            if isinstance(t, str):
                if '_' in t:
                    s, n = t.split('_', 1)
                    bound_tool_keys.add(t)
                    tool_to_server[n] = s
            elif isinstance(t, dict):
                s = t.get('server_name') or t.get('server')
                n = t.get('name') or t.get('tool_name')
                if s and n:
                    bound_tool_keys.add(f"{s}_{n}")
                    tool_to_server[n] = s
        
        return bound_tool_keys, tool_to_server
    
    def _infer_default_tool_calls(self, user_message: str) -> List[str]:
        """åœ¨LLMæœªæ˜¾å¼å‘å‡º TOOL_CALL æ—¶ï¼Œæ ¹æ®å·²ç»‘å®šå·¥å…·æ¨æ–­ä¸€ä¸ªæˆ–å¤šä¸ªé»˜è®¤è°ƒç”¨ã€‚
        ç­–ç•¥ï¼šä¼˜å…ˆé€‰æ‹©åç§°ä¸­åŒ…å« 'search' çš„å·¥å…·ï¼›å¦åˆ™é€‰æ‹©ç¬¬ä¸€ä¸ªç»‘å®šå·¥å…·ã€‚
        è¿”å›å½¢å¦‚ ['server_tool query=xxx'] çš„è°ƒç”¨åˆ—è¡¨ã€‚
        """
        if not self.bound_tools:
            return []
        candidate_calls: List[str] = []
        fallback_call: str = ""
        lower_msg = (user_message or "").strip()
        for t in self.bound_tools:
            if isinstance(t, str):
                server_tool = t
                if not fallback_call:
                    fallback_call = f"{server_tool} {lower_msg}" if lower_msg else server_tool
                if 'search' in server_tool.lower():
                    candidate_calls.append(f"{server_tool} query={lower_msg}" if lower_msg else server_tool)
            elif isinstance(t, dict):
                server = t.get('server_name') or t.get('server')
                name = t.get('name') or t.get('tool_name')
                if server and name:
                    server_tool = f"{server}_{name}"
                    if not fallback_call:
                        fallback_call = f"{server_tool} {lower_msg}" if lower_msg else server_tool
                    if 'search' in name.lower() or 'search' in server.lower():
                        candidate_calls.append(f"{server_tool} query={lower_msg}" if lower_msg else server_tool)
        # å»é‡ï¼Œä¿æŒé¡ºåº
        seen = set()
        ordered = [c for c in candidate_calls if not (c in seen or seen.add(c))]
        if ordered:
            return [ordered[0]]
        return [fallback_call] if fallback_call else []

    async def _satisfaction_check_and_refine(self, user_message: str, initial_answer: str, tool_results: List[Dict[str, Any]]) -> Dict[str, Any]:
        """è®©LLMè¯„ä¼°æ˜¯å¦å·²æ»¡è¶³éœ€æ±‚ï¼Œå¿…è¦æ—¶ç»™å‡ºæ”¹è¿›çš„æŸ¥è¯¢ã€‚è¿”å› { satisfied: bool, refined_query: Optional[str] }"""
        try:
            instruction = (
                "ä½ æ˜¯ä¸€ä¸ªå®¡æ ¸åŠ©æ‰‹ã€‚ç»™å®šç”¨æˆ·é—®é¢˜ã€åˆæ­¥å›ç­”ä»¥åŠå·¥å…·æ£€ç´¢ç»“æœï¼Œåˆ¤æ–­æ˜¯å¦å·²è¶³å¤Ÿå›ç­”ç”¨æˆ·ã€‚"
                "ä»…è¿”å›JSONï¼Œæ ¼å¼ä¸º {\"satisfied\": true|false, \"refined_query\": string|null}ã€‚"
            )
            payload = {
                "role": "system",
                "content": instruction
            }
            context_blob = {
                "user_message": user_message,
                "initial_answer": initial_answer,
                "tool_results": tool_results,
            }
            resp = await self.llm_helper.call(messages=[payload, {"role": "user", "content": json.dumps(context_blob, ensure_ascii=False)}])
            try:
                parsed = json.loads(resp)
                return {
                    "satisfied": bool(parsed.get("satisfied", False)),
                    "refined_query": parsed.get("refined_query")
                }
            except Exception:
                lower = (resp or "").lower()
                return {
                    "satisfied": ("true" in lower and "false" not in lower),
                    "refined_query": None
                }
        except Exception as e:
            logger.warning(f"æ»¡æ„åº¦è¯„ä¼°å¤±è´¥: {str(e)}")
            return {"satisfied": False, "refined_query": None}
    
    async def _execute_tool_call(self, tool_call: str, bound_tool_keys: set, tool_to_server: Dict[str, str], mcp_helper) -> tuple[str, str]:
        """æ‰§è¡Œå•ä¸ªå·¥å…·è°ƒç”¨"""
        try:
            # è§£æå·¥å…·åç§°å’Œå‚æ•°
            parts = tool_call.split(' ', 1)
            if len(parts) < 2:
                return f"å·¥å…·è°ƒç”¨æ ¼å¼ä¸æ­£ç¡®: {tool_call}", ""
            
            tool_name = parts[0].strip()
            tool_params = parts[1].strip()
            
            # æ£€æŸ¥å·¥å…·æ˜¯å¦åœ¨ç»‘å®šåˆ—è¡¨ä¸­
            if not (tool_name in bound_tool_keys or tool_name in tool_to_server):
                return f"å·¥å…· {tool_name} æœªç»‘å®šï¼Œæ— æ³•æ‰§è¡Œ", ""
            
            # è§£æå‚æ•°
            params = {}
            if '=' in tool_params:
                for param in tool_params.split():
                    if '=' in param:
                        key, value = param.split('=', 1)
                        params[key.strip()] = value.strip()
            else:
                # å¦‚æœæ²¡æœ‰=ï¼Œå‡è®¾æ˜¯æŸ¥è¯¢å‚æ•°
                params['query'] = tool_params
            
            # ä»å·¥å…·åä¸­æå–æœåŠ¡å™¨åå’Œå·¥å…·å
            if '_' in tool_name:
                server_name, actual_tool_name = tool_name.split('_', 1)
            else:
                actual_tool_name = tool_name
                server_name = tool_to_server.get(actual_tool_name)
                if not server_name:
                    available_services = await mcp_helper.get_available_services()
                    if available_services:
                        server_name = available_services[0]
                    else:
                        raise RuntimeError("æ²¡æœ‰å¯ç”¨çš„MCPæœåŠ¡å™¨")
            
            # è°ƒç”¨MCPå·¥å…·
            tool_result = await mcp_helper.call_tool(
                server_name=server_name,
                tool_name=actual_tool_name,
                **params
            )
            
            return tool_result, tool_name
            
        except Exception as e:
            logger.error(f"æ‰§è¡Œå·¥å…·è°ƒç”¨å¤±è´¥: {str(e)}")
            return f"å·¥å…·æ‰§è¡Œå¤±è´¥: {str(e)}", ""
    
    async def process_message(self, user_id: str, message: str, context: Dict[str, Any] = None) -> AgentMessage:
        """å¤„ç†ç”¨æˆ·æ¶ˆæ¯ï¼ˆéæµå¼ï¼‰"""
        try:
            # è·å–ç”¨æˆ·ä¸Šä¸‹æ–‡
            agent_context = self.get_context(user_id)
            if not agent_context:
                agent_context = AgentContext(
                    user_id=user_id,
                    session_id=str(uuid.uuid4()),
                    messages=[],
                    metadata={}
                )
                self.update_context(user_id, agent_context)
            
            # æ„å»ºå¯¹è¯å†å²
            conversation_history = []
            for msg in agent_context.messages[-10:]:  # ä¿ç•™æœ€è¿‘10æ¡æ¶ˆæ¯
                if msg.type == MessageType.USER:
                    conversation_history.append({"role": "user", "content": msg.content})
                elif msg.type == MessageType.AGENT:
                    conversation_history.append({"role": "assistant", "content": msg.content})
            
            # æ·»åŠ å½“å‰ç”¨æˆ·æ¶ˆæ¯
            conversation_history.append({"role": "user", "content": message})
            
            # æŸ¥è¯¢çŸ¥è¯†åº“ï¼ˆå¦‚æœæœ‰ç»‘å®šçš„è¯ï¼‰
            knowledge_context = ""
            if self.bound_knowledge_bases:
                try:
                    db_session = context.get('db_session') if context else None
                    knowledge_context = await self.query_knowledge_base(message, db_session)
                except Exception as e:
                    logger.warning(f"çŸ¥è¯†åº“æŸ¥è¯¢å¤±è´¥: {str(e)}")
            
            # æ„å»ºå¢å¼ºçš„ç³»ç»Ÿæç¤ºè¯
            enhanced_system_prompt = self._build_enhanced_system_prompt(knowledge_context)
            
            # è°ƒç”¨LLMç”Ÿæˆå“åº”
            try:
                response_content = await self.llm_helper.call(
                    messages=[
                        {"role": "system", "content": enhanced_system_prompt}
                    ] + conversation_history
                )
            except Exception as e:
                logger.warning(f"LLMè°ƒç”¨å¤±è´¥ï¼Œä½¿ç”¨æ¨¡æ‹Ÿå“åº”: {str(e)}")
                response_content = f"æ‚¨å¥½ï¼æˆ‘æ˜¯{self.name}æ™ºèƒ½ä½“ã€‚æˆ‘æ”¶åˆ°äº†æ‚¨çš„æ¶ˆæ¯ï¼š'{message}'ã€‚å¦‚æœæ‚¨éœ€è¦çœŸå®çš„AIå“åº”ï¼Œè¯·ç¡®ä¿LLMæœåŠ¡æ­£åœ¨è¿è¡Œã€‚"
            
            # å·¥å…·é˜¶æ®µï¼šå…ˆè§£ææ˜¾å¼è°ƒç”¨ï¼Œå¦åˆ™èµ°é»˜è®¤æ¨æ–­
            tools_used = []
            tool_results_pack = []
            tool_calls = []
            if self.bound_tools:
                if "TOOL_CALL:" in response_content:
                    tool_calls = self._parse_tool_calls(response_content)
                if not tool_calls:
                    tool_calls = self._infer_default_tool_calls(message)
                    if tool_calls:
                        logger.info(f"æœªå‘ç°æ˜¾å¼å·¥å…·è°ƒç”¨ï¼Œå·²è‡ªåŠ¨æ¨æ–­è°ƒç”¨: {tool_calls}")
                try:
                    if tool_calls:
                        bound_tool_keys, tool_to_server = self._build_tool_mapping()
                        from main import agent_manager
                        if agent_manager and hasattr(agent_manager, 'mcp_helper'):
                            mcp_helper = agent_manager.mcp_helper
                            for tc in tool_calls:
                                tool_result, tool_name = await self._execute_tool_call(tc, bound_tool_keys, tool_to_server, mcp_helper)
                                if tool_name:
                                    response_content += f"\n\nğŸ” å·¥å…· {tool_name} æ‰§è¡Œç»“æœ:\n{tool_result}"
                                    tools_used.append(tool_name)
                                    tool_results_pack.append({"tool": tool_name, "query": tc, "result": tool_result})
                        else:
                            logger.warning("MCPåŠ©æ‰‹æœªåˆå§‹åŒ–ï¼Œæ— æ³•æ‰§è¡Œå·¥å…·è°ƒç”¨")
                except Exception as e:
                    logger.error(f"å·¥å…·è°ƒç”¨å¤„ç†å¤±è´¥: {str(e)}")
                    response_content += f"\n\nå·¥å…·è°ƒç”¨å¤±è´¥: {str(e)}"

            # æ»¡æ„åº¦æ£€æŸ¥ä¸ä¸€æ¬¡æ€§ä¼˜åŒ–é‡è¯•
            if tool_results_pack:
                check = await self._satisfaction_check_and_refine(message, response_content, tool_results_pack)
                if not check.get("satisfied") and check.get("refined_query"):
                    refined = check["refined_query"]
                    secondary_calls = self._infer_default_tool_calls(refined)
                    try:
                        if secondary_calls:
                            bound_tool_keys, tool_to_server = self._build_tool_mapping()
                            from main import agent_manager
                            if agent_manager and hasattr(agent_manager, 'mcp_helper'):
                                mcp_helper = agent_manager.mcp_helper
                                for tc in secondary_calls:
                                    tool_result, tool_name = await self._execute_tool_call(tc, bound_tool_keys, tool_to_server, mcp_helper)
                                    if tool_name:
                                        response_content += f"\n\nğŸ” äºŒæ¬¡æ£€ç´¢ {tool_name}ï¼ˆä¼˜åŒ–æŸ¥è¯¢ï¼‰æ‰§è¡Œç»“æœ:\n{tool_result}"
                                        tools_used.append(tool_name)
                                        tool_results_pack.append({"tool": tool_name, "query": tc, "result": tool_result, "refined": True})
                            else:
                                logger.warning("MCPåŠ©æ‰‹æœªåˆå§‹åŒ–ï¼Œæ— æ³•æ‰§è¡Œå·¥å…·è°ƒç”¨ï¼ˆä¼˜åŒ–è½®æ¬¡ï¼‰")
                    except Exception as e:
                        logger.error(f"ä¼˜åŒ–è½®æ¬¡å·¥å…·è°ƒç”¨å¤±è´¥: {str(e)}")
                        response_content += f"\n\nä¼˜åŒ–è½®æ¬¡å·¥å…·è°ƒç”¨å¤±è´¥: {str(e)}"

            # åˆ›å»ºå“åº”æ¶ˆæ¯
            response = self.create_message(
                content=response_content,
                message_type=MessageType.AGENT,
                agent_name=self.name
            )
            
            # æ›´æ–°ä¸Šä¸‹æ–‡
            agent_context.messages.append(response)
            self.update_context(user_id, agent_context)
            
            # ä¿å­˜å·¥å…·ä½¿ç”¨ä¿¡æ¯åˆ°å…ƒæ•°æ®
            if tools_used:
                response.metadata = {"tools_used": tools_used}
            
            logger.info(f"é€šç”¨æ™ºèƒ½ä½“ {self.name} å¤„ç†æ¶ˆæ¯å®Œæˆï¼Œä½¿ç”¨å·¥å…·: {tools_used}")
            return response
            
        except Exception as e:
            logger.error(f"é€šç”¨æ™ºèƒ½ä½“å¤„ç†æ¶ˆæ¯å¤±è´¥: {str(e)}")
            error_response = self.create_message(
                content=f"æŠ±æ­‰ï¼Œå¤„ç†æ‚¨çš„æ¶ˆæ¯æ—¶å‡ºç°äº†é”™è¯¯: {str(e)}",
                message_type=MessageType.AGENT,
                agent_name=self.name
            )
            return error_response
    
    async def process_message_stream(self, user_id: str, message: str, context: Dict[str, Any] = None) -> AsyncGenerator[StreamChunk, None]:
        """æµå¼å¤„ç†ç”¨æˆ·æ¶ˆæ¯"""
        try:
            # è·å–ç”¨æˆ·ä¸Šä¸‹æ–‡
            agent_context = self.get_context(user_id)
            if not agent_context:
                agent_context = AgentContext(
                    user_id=user_id,
                    session_id=str(uuid.uuid4()),
                    messages=[],
                    metadata={}
                )
                self.update_context(user_id, agent_context)
            
            # æ„å»ºå¯¹è¯å†å²
            conversation_history = []
            for msg in agent_context.messages[-10:]:  # ä¿ç•™æœ€è¿‘10æ¡æ¶ˆæ¯
                if msg.type == MessageType.USER:
                    conversation_history.append({"role": "user", "content": msg.content})
                elif msg.type == MessageType.AGENT:
                    conversation_history.append({"role": "assistant", "content": msg.content})
            
            # æ·»åŠ å½“å‰ç”¨æˆ·æ¶ˆæ¯
            conversation_history.append({"role": "user", "content": message})
            
            # æŸ¥è¯¢çŸ¥è¯†åº“ï¼ˆå¦‚æœæœ‰ç»‘å®šçš„è¯ï¼‰
            knowledge_context = ""
            if self.bound_knowledge_bases:
                try:
                    db_session = context.get('db_session') if context else None
                    knowledge_context = await self.query_knowledge_base(message, db_session)
                except Exception as e:
                    logger.warning(f"çŸ¥è¯†åº“æŸ¥è¯¢å¤±è´¥: {str(e)}")
            
            # æ„å»ºå¢å¼ºçš„ç³»ç»Ÿæç¤ºè¯
            enhanced_system_prompt = self._build_enhanced_system_prompt(knowledge_context)
            
            # æµå¼è°ƒç”¨LLM
            full_response = ""
            chunk_count = 0
            async for chunk in self.llm_helper.call_stream(
                messages=[
                    {"role": "system", "content": enhanced_system_prompt}
                ] + conversation_history
            ):
                full_response += chunk
                chunk_count += 1
                yield StreamChunk(
                    chunk_id=f"{user_id}_{chunk_count}",
                    session_id=agent_context.session_id,
                    type="content",
                    content=chunk,
                    agent_name=self.name
                )
            
            # å·¥å…·é˜¶æ®µï¼šå…ˆè§£ææ˜¾å¼è°ƒç”¨ï¼Œå¦åˆ™èµ°é»˜è®¤æ¨æ–­
            tools_used = []
            tool_results_pack = []
            tool_calls = []
            if self.bound_tools:
                if "TOOL_CALL:" in full_response:
                    tool_calls = self._parse_tool_calls(full_response)
                if not tool_calls:
                    tool_calls = self._infer_default_tool_calls(message)
                    if tool_calls:
                        logger.info(f"æœªå‘ç°æ˜¾å¼å·¥å…·è°ƒç”¨ï¼Œå·²è‡ªåŠ¨æ¨æ–­è°ƒç”¨: {tool_calls}")
                try:
                    if tool_calls:
                        bound_tool_keys, tool_to_server = self._build_tool_mapping()
                        from main import agent_manager
                        if agent_manager and hasattr(agent_manager, 'mcp_helper'):
                            mcp_helper = agent_manager.mcp_helper
                            for tc in tool_calls:
                                tool_result, tool_name = await self._execute_tool_call(tc, bound_tool_keys, tool_to_server, mcp_helper)
                                if tool_name:
                                    formatted_result = f"\n\nğŸ” å·¥å…· {tool_name} æ‰§è¡Œç»“æœ:\n{tool_result}\n"
                                    # å°†å·¥å…·ç»“æœä¹Ÿç´¯ç§¯åˆ°æœ€ç»ˆå…¨æ–‡ä¸­ï¼Œç¡®ä¿å‰ç«¯å³ä¾¿åªå±•ç¤ºæœ€ç»ˆå—ä¹Ÿèƒ½çœ‹åˆ°
                                    full_response += formatted_result
                                    yield StreamChunk(
                                        chunk_id=f"{user_id}_tool_{tool_name}",
                                        session_id=agent_context.session_id,
                                        type="tool_result",
                                        content=formatted_result,
                                        metadata={"tool_name": tool_name},
                                        agent_name=self.name
                                    )
                                    # å…¼å®¹å‰ç«¯ä»…å±•ç¤º content ç±»å‹çš„æƒ…å†µï¼Œå†è¿½åŠ ä¸€æ¡å†…å®¹å—
                                    yield StreamChunk(
                                        chunk_id=f"{user_id}_tool_{tool_name}_content",
                                        session_id=agent_context.session_id,
                                        type="content",
                                        content=formatted_result,
                                        agent_name=self.name
                                    )
                                    tools_used.append(tool_name)
                                    tool_results_pack.append({"tool": tool_name, "query": tc, "result": tool_result})
                        else:
                            logger.warning("MCPåŠ©æ‰‹æœªåˆå§‹åŒ–ï¼Œæ— æ³•æ‰§è¡Œå·¥å…·è°ƒç”¨")
                except Exception as e:
                    logger.error(f"å·¥å…·è°ƒç”¨å¤„ç†å¤±è´¥: {str(e)}")
                    yield StreamChunk(
                        chunk_id=f"{user_id}_tool_error",
                        session_id=agent_context.session_id,
                        type="tool_error",
                        content=f"\n\nå·¥å…·è°ƒç”¨å¤±è´¥: {str(e)}",
                        agent_name=self.name
                    )

            # æ»¡æ„åº¦æ£€æŸ¥ä¸ä¸€æ¬¡ä¼˜åŒ–è½®
            if tool_results_pack:
                check = await self._satisfaction_check_and_refine(message, full_response, tool_results_pack)
                if not check.get("satisfied") and check.get("refined_query"):
                    refined = check["refined_query"]
                    secondary_calls = self._infer_default_tool_calls(refined)
                    try:
                        if secondary_calls:
                            bound_tool_keys, tool_to_server = self._build_tool_mapping()
                            from main import agent_manager
                            if agent_manager and hasattr(agent_manager, 'mcp_helper'):
                                mcp_helper = agent_manager.mcp_helper
                                for tc in secondary_calls:
                                    tool_result, tool_name = await self._execute_tool_call(tc, bound_tool_keys, tool_to_server, mcp_helper)
                                    if tool_name:
                                        formatted_result = f"\n\nğŸ” äºŒæ¬¡æ£€ç´¢ {tool_name}ï¼ˆä¼˜åŒ–æŸ¥è¯¢ï¼‰æ‰§è¡Œç»“æœ:\n{tool_result}\n"
                                        full_response += formatted_result
                                        yield StreamChunk(
                                            chunk_id=f"{user_id}_tool2_{tool_name}",
                                            session_id=agent_context.session_id,
                                            type="tool_result",
                                            content=formatted_result,
                                            metadata={"tool_name": tool_name, "refined": True},
                                            agent_name=self.name
                                        )
                                        # å…¼å®¹å‰ç«¯ä»…å±•ç¤º content ç±»å‹çš„æƒ…å†µï¼Œå†è¿½åŠ ä¸€æ¡å†…å®¹å—
                                        yield StreamChunk(
                                            chunk_id=f"{user_id}_tool2_{tool_name}_content",
                                            session_id=agent_context.session_id,
                                            type="content",
                                            content=formatted_result,
                                            agent_name=self.name
                                        )
                                        tools_used.append(tool_name)
                                        tool_results_pack.append({"tool": tool_name, "query": tc, "result": tool_result, "refined": True})
                            else:
                                logger.warning("MCPåŠ©æ‰‹æœªåˆå§‹åŒ–ï¼Œæ— æ³•æ‰§è¡Œå·¥å…·è°ƒç”¨ï¼ˆä¼˜åŒ–è½®æ¬¡ï¼‰")
                    except Exception as e:
                        logger.error(f"ä¼˜åŒ–è½®æ¬¡å·¥å…·è°ƒç”¨å¤±è´¥: {str(e)}")
                        yield StreamChunk(
                            chunk_id=f"{user_id}_tool2_error",
                            session_id=agent_context.session_id,
                            type="tool_error",
                            content=f"\n\nä¼˜åŒ–è½®æ¬¡å·¥å…·è°ƒç”¨å¤±è´¥: {str(e)}",
                            agent_name=self.name
                        )

            # å‘é€æœ€ç»ˆå“åº”å—ï¼ŒåŒ…å«å®Œæ•´çš„å“åº”å†…å®¹
            yield StreamChunk(
                chunk_id=f"{user_id}_final",
                session_id=agent_context.session_id,
                type="final",
                content=full_response,
                metadata={"tools_used": tools_used},
                agent_name=self.name
            )
            
            # æ›´æ–°å¯¹è¯å†å²
            agent_context.messages.append(AgentMessage(
                message_id=str(uuid.uuid4()),
                user_id=user_id,
                type=MessageType.USER,
                content=message,
                timestamp=asyncio.get_event_loop().time()
            ))
            
            agent_context.messages.append(AgentMessage(
                message_id=str(uuid.uuid4()),
                user_id=user_id,
                type=MessageType.AGENT,
                content=full_response,
                timestamp=asyncio.get_event_loop().time(),
                metadata={"tools_used": tools_used}
            ))
            
            self.update_context(user_id, agent_context)
            logger.info(f"æ™ºèƒ½ä½“ {self.name} æµå¼å¤„ç†æ¶ˆæ¯å®Œæˆï¼Œå“åº”é•¿åº¦: {len(full_response)}, ä½¿ç”¨å·¥å…·: {tools_used}")
            
        except Exception as e:
            logger.error(f"é€šç”¨æ™ºèƒ½ä½“æµå¼å¤„ç†æ¶ˆæ¯å¤±è´¥: {str(e)}")
            yield StreamChunk(
                chunk_id=f"{user_id}_error",
                session_id=agent_context.session_id,
                type="error",
                content=f"æŠ±æ­‰ï¼Œå¤„ç†æ‚¨çš„æ¶ˆæ¯æ—¶å‡ºç°äº†é”™è¯¯: {str(e)}",
                agent_name=self.name
            ) 