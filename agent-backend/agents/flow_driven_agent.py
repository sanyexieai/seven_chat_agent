from typing import Dict, Any, AsyncGenerator, List, Optional
from agents.base_agent import BaseAgent
from models.chat_models import AgentMessage, StreamChunk, MessageType, AgentContext
from utils.log_helper import get_logger
from utils.llm_helper import get_llm_helper
import asyncio
import json
import uuid
from enum import Enum

logger = get_logger("flow_driven_agent")

class NodeType(str, Enum):
    """èŠ‚ç‚¹ç±»å‹æšä¸¾"""
    AGENT = "agent"           # æ™ºèƒ½ä½“èŠ‚ç‚¹
    CONDITION = "condition"    # æ¡ä»¶èŠ‚ç‚¹
    ACTION = "action"         # åŠ¨ä½œèŠ‚ç‚¹
    LLM = "llm"               # LLM è°ƒç”¨èŠ‚ç‚¹
    TOOL = "tool"             # å·¥å…·è°ƒç”¨èŠ‚ç‚¹

class FlowNode:
    """æµç¨‹å›¾èŠ‚ç‚¹"""
    def __init__(self, node_id: str, node_type: NodeType, name: str, config: Dict[str, Any] = None):
        self.id = node_id
        self.type = node_type
        self.name = name
        self.config = config or {}
        self.position = self.config.get('position', {'x': 0, 'y': 0})
        self.connections = self.config.get('connections', [])  # è¿æ¥åˆ°çš„å…¶ä»–èŠ‚ç‚¹IDåˆ—è¡¨

class FlowDrivenAgent(BaseAgent):
    """æµç¨‹å›¾é©±åŠ¨æ™ºèƒ½ä½“
    
    é€šè¿‡åœ¨çº¿ç¼–è¾‘æµç¨‹å›¾çš„å½¢å¼ï¼Œå°†å…¶ä»–åŸºç¡€æ™ºèƒ½ä½“ä½œä¸ºèŠ‚ç‚¹åˆ›å»ºå¤æ‚çš„å¤šæ™ºèƒ½ä½“ç»„åˆã€‚
    æ”¯æŒæ¡ä»¶åˆ†æ”¯ã€å¾ªç¯ã€å¹¶è¡Œæ‰§è¡Œç­‰å¤æ‚çš„æµç¨‹æ§åˆ¶ã€‚
    """
    
    def __init__(self, name: str, description: str, flow_config: Dict[str, Any] = None):
        super().__init__(name, description)
        
        # æµç¨‹å›¾é…ç½®
        self.flow_config = flow_config or {}
        self.nodes = {}  # èŠ‚ç‚¹å­—å…¸ {node_id: FlowNode}
        self.start_node_id = None  # èµ·å§‹èŠ‚ç‚¹ID
        
        # åˆå§‹åŒ–LLMåŠ©æ‰‹
        try:
            self.llm_helper = get_llm_helper()
            logger.info(f"æµç¨‹å›¾é©±åŠ¨æ™ºèƒ½ä½“ {name} åˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            logger.error(f"LLMåˆå§‹åŒ–å¤±è´¥: {str(e)}")
            raise
        
        # åŠ è½½æµç¨‹å›¾é…ç½®
        self._load_flow_config()
        logger.info(f"æµç¨‹å›¾é©±åŠ¨æ™ºèƒ½ä½“ {name} åˆå§‹åŒ–å®Œæˆ")
    
    def _load_flow_config(self):
        """åŠ è½½æµç¨‹å›¾é…ç½®"""
        self.nodes = {}
        self.start_node_id = None
        
        try:
            if not self.flow_config:
                logger.warning("æµç¨‹å›¾é…ç½®ä¸ºç©º")
                return
            
            # è§£æèŠ‚ç‚¹é…ç½®
            nodes_config = self.flow_config.get('nodes', [])
            logger.info(f"å¼€å§‹è§£æ {len(nodes_config)} ä¸ªèŠ‚ç‚¹")
            
            for node_config in nodes_config:
                node_id = node_config.get('id')
                node_type = NodeType(node_config.get('type', 'agent'))
                node_data = node_config.get('data', {})
                node_name = node_data.get('label', '')
                
                # ä»dataä¸­æå–config
                node_config_dict = node_data.get('config', {})
                
                logger.info(f"è§£æèŠ‚ç‚¹ {node_id}: type={node_type}, name={node_name}, config={node_config_dict}")
                
                node = FlowNode(node_id, node_type, node_name, node_config_dict)
                self.nodes[node_id] = node
                
                # æ£€æŸ¥æ˜¯å¦ä¸ºèµ·å§‹èŠ‚ç‚¹
                if node_data.get('isStartNode', False):
                    self.start_node_id = node_id
                    logger.info(f"è®¾ç½®èµ·å§‹èŠ‚ç‚¹: {node_id}")
            
            # å¦‚æœæ²¡æœ‰æ‰¾åˆ°èµ·å§‹èŠ‚ç‚¹ï¼Œä½¿ç”¨ç¬¬ä¸€ä¸ªèŠ‚ç‚¹ä½œä¸ºèµ·å§‹èŠ‚ç‚¹
            if not self.start_node_id and nodes_config:
                self.start_node_id = nodes_config[0]['id']
                logger.info(f"æœªæ‰¾åˆ°èµ·å§‹èŠ‚ç‚¹ï¼Œä½¿ç”¨ç¬¬ä¸€ä¸ªèŠ‚ç‚¹ä½œä¸ºèµ·å§‹èŠ‚ç‚¹: {self.start_node_id}")
            
            logger.info(f"åŠ è½½äº† {len(self.nodes)} ä¸ªæµç¨‹å›¾èŠ‚ç‚¹")
            logger.info(f"èµ·å§‹èŠ‚ç‚¹: {self.start_node_id}")
            
            # æ‰“å°æ‰€æœ‰èŠ‚ç‚¹çš„é…ç½®
            for node_id, node in self.nodes.items():
                logger.info(f"èŠ‚ç‚¹ {node_id} é…ç½®: {node.config}")
            
        except Exception as e:
            logger.error(f"åŠ è½½æµç¨‹å›¾é…ç½®å¤±è´¥: {str(e)}")
    
    def set_flow_config(self, config: Dict[str, Any]):
        """è®¾ç½®æµç¨‹å›¾é…ç½®"""
        self.flow_config = config
        self._load_flow_config()
        logger.info(f"æ™ºèƒ½ä½“ {self.name} æµç¨‹å›¾é…ç½®å·²æ›´æ–°")
    
    def get_flow_config(self) -> Dict[str, Any]:
        """è·å–æµç¨‹å›¾é…ç½®"""
        return self.flow_config
    
    def add_node(self, node_id: str, node_type: NodeType, name: str, config: Dict[str, Any] = None):
        """æ·»åŠ èŠ‚ç‚¹"""
        node = FlowNode(node_id, node_type, name, config)
        self.nodes[node_id] = node
        logger.info(f"æ·»åŠ èŠ‚ç‚¹: {node_id} ({node_type.value})")
    
    def remove_node(self, node_id: str):
        """åˆ é™¤èŠ‚ç‚¹"""
        if node_id in self.nodes:
            del self.nodes[node_id]
            logger.info(f"åˆ é™¤èŠ‚ç‚¹: {node_id}")
    
    def connect_nodes(self, from_node_id: str, to_node_id: str):
        """è¿æ¥èŠ‚ç‚¹"""
        if from_node_id in self.nodes and to_node_id in self.nodes:
            if to_node_id not in self.nodes[from_node_id].connections:
                self.nodes[from_node_id].connections.append(to_node_id)
                logger.info(f"è¿æ¥èŠ‚ç‚¹: {from_node_id} -> {to_node_id}")
    
    async def execute_flow(self, user_id: str, message: str, context: Dict[str, Any] = None) -> AgentMessage:
        """æ‰§è¡Œæµç¨‹å›¾"""
        if not self.start_node_id:
            return AgentMessage(
                id=str(uuid.uuid4()),
                type=MessageType.AGENT,
                content="æµç¨‹å›¾æœªé…ç½®èµ·å§‹èŠ‚ç‚¹ï¼Œæ— æ³•æ‰§è¡Œã€‚",
                agent_name=self.name,
                metadata={'flow_executed': False, 'error': 'no_start_node'}
            )
        
        try:
            logger.info(f"å¼€å§‹æ‰§è¡Œæµç¨‹å›¾ï¼Œèµ·å§‹èŠ‚ç‚¹: {self.start_node_id}")
            logger.info(f"ç”¨æˆ·æ¶ˆæ¯: {message}")
            
            # ç›´æ¥æ‰§è¡Œèµ·å§‹èŠ‚ç‚¹ï¼Œä¼ å…¥ç”¨æˆ·æ¶ˆæ¯
            response = await self._execute_node(self.start_node_id, user_id, message, context)
            
            logger.info(f"æµç¨‹å›¾æ‰§è¡Œå®Œæˆ")
            return response
            
        except Exception as e:
            logger.error(f"æ‰§è¡Œæµç¨‹å›¾å¤±è´¥: {str(e)}")
            return AgentMessage(
                id=str(uuid.uuid4()),
                type=MessageType.AGENT,
                content=f"æµç¨‹å›¾æ‰§è¡Œå¤±è´¥: {str(e)}",
                agent_name=self.name,
                metadata={'flow_executed': False, 'error': str(e)}
            )
    
    async def _execute_node(self, node_id: str, user_id: str, message: str, context: Dict[str, Any]) -> AgentMessage:
        """æ‰§è¡ŒèŠ‚ç‚¹"""
        node = self.nodes.get(node_id)
        if not node:
            raise ValueError(f"èŠ‚ç‚¹ {node_id} ä¸å­˜åœ¨")
        
        logger.info(f"æ‰§è¡ŒèŠ‚ç‚¹: {node_id} ({node.type})")
        
        try:
            if node.type == NodeType.AGENT:
                return await self._execute_agent_node(node, user_id, message, context)
            elif node.type == NodeType.CONDITION:
                return await self._execute_condition_node(node, user_id, message, context)
            elif node.type == NodeType.ACTION:
                return await self._execute_action_node(node, user_id, message, context)
            elif node.type == NodeType.LLM:
                return await self._execute_llm_node(node, user_id, message, context)
            elif node.type == NodeType.TOOL:
                return await self._execute_tool_node(node, user_id, message, context)
            else:
                raise ValueError(f"ä¸æ”¯æŒçš„èŠ‚ç‚¹ç±»å‹: {node.type}")
        except Exception as e:
            logger.error(f"æ‰§è¡ŒèŠ‚ç‚¹ {node_id} å¤±è´¥: {str(e)}")
            raise

    def _get_flow_state(self, context: Optional[Dict[str, Any]]) -> Dict[str, Any]:
        """ä»ä¸Šä¸‹æ–‡è·å–/åˆå§‹åŒ–æµç¨‹çŠ¶æ€å®¹å™¨ã€‚"""
        if context is None:
            context = {}
        state = context.get('flow_state')
        if state is None:
            state = {}
            context['flow_state'] = state
        return state

    def _render_template_value(self, value: Any, variables: Dict[str, Any]) -> Any:
        """æ¸²æŸ“å­—ç¬¦ä¸²ä¸­çš„ {{var}} æ¨¡æ¿ï¼›å¯¹ dict/list é€’å½’å¤„ç†ã€‚"""
        if isinstance(value, str):
            result = value
            for k, v in variables.items():
                placeholder = f"{{{{{k}}}}}"
                try:
                    result = result.replace(placeholder, str(v))
                except Exception:
                    pass
            return result
        if isinstance(value, dict):
            return {k: self._render_template_value(v, variables) for k, v in value.items()}
        if isinstance(value, list):
            return [self._render_template_value(v, variables) for v in value]
        return value

    async def _execute_llm_node(self, node: FlowNode, user_id: str, message: str, context: Dict[str, Any]) -> AgentMessage:
        """æ‰§è¡Œ LLM èŠ‚ç‚¹ã€‚
        é…ç½®ï¼š
        - system_prompt: å¯é€‰ï¼Œç³»ç»Ÿæç¤ºè¯æ¨¡æ¿
        - user_prompt: å¯é€‰ï¼Œç”¨æˆ·æç¤ºè¯æ¨¡æ¿ï¼›è‹¥ç¼ºçœåˆ™ä½¿ç”¨ä¼ å…¥ message
        - save_as: å¯é€‰ï¼Œå°†è¾“å‡ºä¿å­˜åˆ° flow_state çš„å˜é‡åï¼Œé»˜è®¤ 'last_output'
        """
        flow_state = self._get_flow_state(context)
        variables = {**flow_state, 'message': message}
        system_prompt = self._render_template_value(node.config.get('system_prompt', ''), variables)
        user_prompt = self._render_template_value(node.config.get('user_prompt', message), variables)
        save_as = node.config.get('save_as', 'last_output')
        
        logger.info(f"LLMèŠ‚ç‚¹ {node.id} å¼€å§‹æ‰§è¡Œ")
        try:
            if system_prompt:
                content = await self.llm_helper.call(messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ])
            else:
                content = await self.llm_helper.call(messages=[
                    {"role": "user", "content": user_prompt}
                ])
            flow_state[save_as] = content
            flow_state['last_output'] = content
            logger.info(f"LLMèŠ‚ç‚¹ {node.id} æ‰§è¡Œå®Œæˆï¼Œä¿å­˜ä¸º {save_as}")
        except Exception as e:
            logger.error(f"LLMèŠ‚ç‚¹æ‰§è¡Œå¤±è´¥: {str(e)}")
            content = f"LLMèŠ‚ç‚¹æ‰§è¡Œå¤±è´¥: {str(e)}"
            flow_state[save_as] = content
            flow_state['last_output'] = content
        
        # è·³è½¬åˆ°ä¸‹ä¸€ä¸ªèŠ‚ç‚¹æˆ–è¿”å›
        if node.connections:
            next_node_id = node.connections[0]
            return await self._execute_node(next_node_id, user_id, message, context)
        return AgentMessage(
            id=str(uuid.uuid4()),
            type=MessageType.AGENT,
            content=flow_state['last_output'],
            agent_name=self.name,
            metadata={'node_id': node.id, 'node_type': node.type.value}
        )

    async def _execute_tool_node(self, node: FlowNode, user_id: str, message: str, context: Dict[str, Any]) -> AgentMessage:
        """æ‰§è¡Œ å·¥å…· èŠ‚ç‚¹ã€‚
        é…ç½®ï¼š
        - server: æœåŠ¡åï¼ˆå¯é€‰ï¼Œå¦‚æœå·¥å…·ååŒ…å« server_ å‰ç¼€å¯ç¼ºçœï¼‰
        - tool: å·¥å…·åï¼ˆå¿…å¡«ï¼‰
        - params: dict/str å‚æ•°æ¨¡æ¿ï¼Œæ”¯æŒ {{message}} / {{last_output}} / å…¶å®ƒ flow_state å˜é‡
        - save_as: å¯é€‰ï¼Œä¿å­˜ç»“æœå˜é‡åï¼Œé»˜è®¤ 'last_output'
        - append_to_output: boolï¼Œå¯é€‰ï¼Œæ˜¯å¦å°†ç»“æœé™„åŠ åˆ° last_outputï¼ˆé»˜è®¤ Trueï¼‰
        """
        flow_state = self._get_flow_state(context)
        variables = {**flow_state, 'message': message}
        server = self._render_template_value(node.config.get('server'), variables)
        tool = self._render_template_value(node.config.get('tool'), variables)
        raw_params = node.config.get('params', {})
        params = self._render_template_value(raw_params, variables)
        save_as = node.config.get('save_as', 'last_output')
        append_to_output = node.config.get('append_to_output', True)
        
        if not tool:
            raise ValueError(f"å·¥å…·èŠ‚ç‚¹ {node.id} æœªé…ç½® tool åç§°")
        
        try:
            from main import agent_manager
            if not agent_manager or not getattr(agent_manager, 'mcp_helper', None):
                raise RuntimeError("MCPåŠ©æ‰‹æœªåˆå§‹åŒ–")
            mcp_helper = agent_manager.mcp_helper
            actual_server = server
            actual_tool = tool
            # å¦‚æœ tool ç±»ä¼¼ server_tool åˆå¹¶åœ¨ä¸€èµ·ï¼Œåˆ™æ‹†åˆ†
            if '_' in tool and not server:
                parts = tool.split('_', 1)
                actual_server = parts[0]
                actual_tool = parts[1]
            if not actual_server:
                # è‹¥ä»æ— æœåŠ¡åï¼Œé€‰ç¬¬ä¸€ä¸ªå¯ç”¨æœåŠ¡
                services = await mcp_helper.get_available_services()
                if not services:
                    raise RuntimeError("æ²¡æœ‰å¯ç”¨çš„MCPæœåŠ¡")
                actual_server = services[0]
            logger.info(f"å·¥å…·èŠ‚ç‚¹ {node.id} è°ƒç”¨: {actual_server}.{actual_tool} å‚æ•°: {params}")
            result = await mcp_helper.call_tool(server_name=actual_server, tool_name=actual_tool, **(params if isinstance(params, dict) else {"query": str(params)}))
            try:
                serializable = json.dumps(result, ensure_ascii=False)
                result_text = serializable
            except Exception:
                result_text = str(result)
            
            # ä¿å­˜ç»“æœ
            flow_state[save_as] = result
            if append_to_output:
                prev = str(flow_state.get('last_output', ''))
                flow_state['last_output'] = f"{prev}\n\nğŸ”§ å·¥å…· {actual_server}_{actual_tool} ç»“æœ:\n{result_text}" if prev else result_text
            else:
                flow_state['last_output'] = result_text
            logger.info(f"å·¥å…·èŠ‚ç‚¹ {node.id} æ‰§è¡Œå®Œæˆï¼Œç»“æœå·²ä¿å­˜ä¸º {save_as}")
        except Exception as e:
            logger.error(f"å·¥å…·èŠ‚ç‚¹æ‰§è¡Œå¤±è´¥: {str(e)}")
            flow_state['last_output'] = f"å·¥å…·èŠ‚ç‚¹æ‰§è¡Œå¤±è´¥: {str(e)}"
            flow_state[save_as] = None
        
        # è·³è½¬åˆ°ä¸‹ä¸€ä¸ªèŠ‚ç‚¹æˆ–è¿”å›
        if node.connections:
            next_node_id = node.connections[0]
            return await self._execute_node(next_node_id, user_id, message, context)
        return AgentMessage(
            id=str(uuid.uuid4()),
            type=MessageType.AGENT,
            content=str(flow_state.get('last_output', '')),
            agent_name=self.name,
            metadata={'node_id': node.id, 'node_type': node.type.value}
        )
    
    async def _execute_agent_node(self, node: FlowNode, user_id: str, message: str, context: Dict[str, Any]) -> AgentMessage:
        """æ‰§è¡Œæ™ºèƒ½ä½“èŠ‚ç‚¹"""
        agent_name = node.config.get('agent_name')
        if not agent_name:
            raise ValueError(f"æ™ºèƒ½ä½“èŠ‚ç‚¹ {node.id} æœªé…ç½®æ™ºèƒ½ä½“åç§°")
        
        try:
            # å°è¯•ä»AgentManagerè·å–å¯¹åº”çš„æ™ºèƒ½ä½“
            from main import agent_manager
            if agent_manager and agent_name in agent_manager.agents:
                # ä½¿ç”¨å®é™…çš„æ™ºèƒ½ä½“
                target_agent = agent_manager.agents[agent_name]
                response = await target_agent.process_message(user_id, message, context)
                return response
            else:
                # å¦‚æœæ‰¾ä¸åˆ°æ™ºèƒ½ä½“ï¼Œä½¿ç”¨LLMæ¨¡æ‹Ÿ
                prompt = f"ä½œä¸ºæ™ºèƒ½ä½“ '{agent_name}'ï¼Œè¯·å¤„ç†ä»¥ä¸‹ç”¨æˆ·æ¶ˆæ¯ï¼š\n{message}"
                response = await self.llm_helper.call(
                    messages=[{"role": "user", "content": prompt}]
                )
                
                return AgentMessage(
                    id=str(uuid.uuid4()),
                    type=MessageType.AGENT,
                    content=response,
                    agent_name=f"{self.name}->{agent_name}",
                    metadata={'node_id': node.id, 'node_type': node.type.value, 'agent_name': agent_name}
                )
        except Exception as e:
            logger.error(f"æ‰§è¡Œæ™ºèƒ½ä½“èŠ‚ç‚¹å¤±è´¥: {str(e)}")
            raise
    
    async def _execute_condition_node(self, node: FlowNode, user_id: str, message: str, context: Dict[str, Any]) -> AgentMessage:
        """æ‰§è¡Œæ¡ä»¶èŠ‚ç‚¹"""
        condition = node.config.get('condition', '')
        if not condition:
            raise ValueError(f"æ¡ä»¶èŠ‚ç‚¹ {node.id} æœªé…ç½®æ¡ä»¶")
        
        # ä½¿ç”¨LLMåˆ¤æ–­æ¡ä»¶ï¼Œæ”¯æŒå¼•ç”¨ flow_state
        flow_state = self._get_flow_state(context)
        variables = {**flow_state, 'message': message}
        rendered_condition = self._render_template_value(condition, variables)
        prompt = (
            "è¯·åŸºäºä»¥ä¸‹ä¿¡æ¯åˆ¤æ–­æ¡ä»¶æ˜¯å¦æˆç«‹ï¼Œä¸¥æ ¼åªå›ç­” true æˆ– falseã€‚\n"
            f"æ¡ä»¶ï¼š{rendered_condition}\n"
            f"ç”¨æˆ·æ¶ˆæ¯ï¼š{message}\n"
            f"æµç¨‹çŠ¶æ€ï¼ˆJSONï¼‰ï¼š{json.dumps(flow_state, ensure_ascii=False)}\n"
        )
        
        try:
            response = await self.llm_helper.call(
                messages=[{"role": "user", "content": prompt}]
            )
            
            # è§£æç»“æœ
            is_true = 'true' in response.lower()
            
            # æ ¹æ®æ¡ä»¶é€‰æ‹©ä¸‹ä¸€ä¸ªèŠ‚ç‚¹
            next_node_id = None
            if is_true and node.connections:
                next_node_id = node.connections[0]  # ç¬¬ä¸€ä¸ªè¿æ¥ä¸ºtrueåˆ†æ”¯
            elif len(node.connections) > 1:
                next_node_id = node.connections[1]  # ç¬¬äºŒä¸ªè¿æ¥ä¸ºfalseåˆ†æ”¯
            
            if next_node_id:
                return await self._execute_node(next_node_id, user_id, message, context)
            else:
                return AgentMessage(
                    id=str(uuid.uuid4()),
                    type=MessageType.AGENT,
                    content=f"æ¡ä»¶åˆ¤æ–­ç»“æœï¼š{is_true}ï¼Œä½†æœªæ‰¾åˆ°åç»­èŠ‚ç‚¹",
                    agent_name=self.name,
                    metadata={'node_id': node.id, 'node_type': node.type.value, 'condition_result': is_true}
                )
        except Exception as e:
            logger.error(f"æ‰§è¡Œæ¡ä»¶èŠ‚ç‚¹å¤±è´¥: {str(e)}")
            raise
    
    async def _execute_action_node(self, node: FlowNode, user_id: str, message: str, context: Dict[str, Any]) -> AgentMessage:
        """æ‰§è¡ŒåŠ¨ä½œèŠ‚ç‚¹"""
        action = node.config.get('action', '')
        if not action:
            raise ValueError(f"åŠ¨ä½œèŠ‚ç‚¹ {node.id} æœªé…ç½®åŠ¨ä½œ")
        
        # æ‰§è¡ŒåŠ¨ä½œï¼ˆè¿™é‡Œå¯ä»¥æ‰©å±•ä¸ºè°ƒç”¨å…·ä½“çš„å·¥å…·æˆ–APIï¼‰
        result = f"æ‰§è¡ŒåŠ¨ä½œï¼š{action}"
        
        # å¦‚æœæœ‰åç»­èŠ‚ç‚¹ï¼Œç»§ç»­æ‰§è¡Œ
        if node.connections:
            next_node_id = node.connections[0]
            return await self._execute_node(next_node_id, user_id, message, context)
        else:
            return AgentMessage(
                id=str(uuid.uuid4()),
                type=MessageType.AGENT,
                content=result,
                agent_name=self.name,
                metadata={'node_id': node.id, 'node_type': node.type.value, 'action': action}
            )
    
    async def process_message(self, user_id: str, message: str, context: Dict[str, Any] = None) -> AgentMessage:
        """å¤„ç†ç”¨æˆ·æ¶ˆæ¯"""
        return await self.execute_flow(user_id, message, context)
    
    async def process_message_stream(self, user_id: str, message: str, context: Dict[str, Any] = None) -> AsyncGenerator[StreamChunk, None]:
        """æµå¼å¤„ç†ç”¨æˆ·æ¶ˆæ¯ï¼šæŒ‰èŠ‚ç‚¹æ‰§è¡Œå¹¶é€æ­¥è¾“å‡ºã€‚
        - LLM èŠ‚ç‚¹ï¼šä½¿ç”¨ call_stream æŒ‰å—è¾“å‡º type="content"
        - TOOL èŠ‚ç‚¹ï¼šå·¥å…·æ‰§è¡Œå®Œæˆåè¾“å‡º type="tool_result"
        - å…¶ä»–èŠ‚ç‚¹ï¼šæ•´ä½“å†…å®¹ä½œä¸ºä¸€æ®µ type="content"
        - æœ€ç»ˆï¼šè¾“å‡º type="final"
        """
        try:
            flow_state = self._get_flow_state(context)
            base_vars = {"message": message}

            if not self.start_node_id:
                yield StreamChunk(
                    chunk_id=str(uuid.uuid4()),
                    session_id=(context or {}).get('session_id', ''),
                    type="error",
                    content="æµç¨‹å›¾æœªé…ç½®èµ·å§‹èŠ‚ç‚¹ï¼Œæ— æ³•æ‰§è¡Œã€‚",
                    agent_name=self.name,
                    metadata={'flow_executed': False, 'error': 'no_start_node'},
                    is_end=True
                )
                return

            current_id = self.start_node_id
            step_guard = 0

            while current_id and step_guard < 1000:
                step_guard += 1
                node = self.nodes.get(current_id)
                if not node:
                    break

                vars_all = {**flow_state, **base_vars}

                if node.type == NodeType.LLM:
                    # æ¸²æŸ“æç¤º
                    system_prompt = self._render_template_value(node.config.get('system_prompt', ''), vars_all)
                    user_prompt = self._render_template_value(node.config.get('user_prompt', message), vars_all)
                    save_as = node.config.get('save_as', 'last_output')

                    try:
                        msgs = []
                        if system_prompt:
                            msgs.append({"role": "system", "content": system_prompt})
                        msgs.append({"role": "user", "content": user_prompt})

                        acc = ""
                        async for piece in self.llm_helper.call_stream(messages=msgs):
                            if not piece:
                                continue
                            acc += piece
                            flow_state['last_output'] = flow_state.get('last_output', '') + piece
                            # æµå¼è¾“å‡º
                            yield StreamChunk(
                                chunk_id=str(uuid.uuid4()),
                                session_id=(context or {}).get('session_id', ''),
                                type="content",
                                content=piece,
                                agent_name=self.name
                            )
                        flow_state[save_as] = acc
                    except Exception as e:
                        yield StreamChunk(
                            chunk_id=str(uuid.uuid4()),
                            session_id=(context or {}).get('session_id', ''),
                            type="error",
                            content=f"LLMèŠ‚ç‚¹æ‰§è¡Œå¤±è´¥: {str(e)}",
                            agent_name=self.name
                        )
                    # ä¸‹ä¸€ä¸ª
                    nexts = node.connections or []
                    current_id = nexts[0] if nexts else None
                    continue

                if node.type == NodeType.TOOL:
                    server = self._render_template_value(node.config.get('server'), vars_all)
                    tool = self._render_template_value(node.config.get('tool'), vars_all)
                    params_raw = node.config.get('params', {})
                    params = self._render_template_value(params_raw, vars_all)
                    save_as = node.config.get('save_as', 'last_output')
                    append_to_output = node.config.get('append_to_output', True)

                    try:
                        from main import agent_manager
                        if not agent_manager or not getattr(agent_manager, 'mcp_helper', None):
                            raise RuntimeError("MCPåŠ©æ‰‹æœªåˆå§‹åŒ–")
                        mcp = agent_manager.mcp_helper

                        actual_server = server
                        actual_tool = tool
                        if tool and '_' in tool and not server:
                            parts = tool.split('_', 1)
                            actual_server = parts[0]
                            actual_tool = parts[1]
                        if not actual_server:
                            services = await mcp.get_available_services()
                            if not services:
                                raise RuntimeError("æ²¡æœ‰å¯ç”¨çš„MCPæœåŠ¡")
                            actual_server = services[0]

                        result = await mcp.call_tool(
                            server_name=actual_server,
                            tool_name=actual_tool,
                            **(params if isinstance(params, dict) else {"query": str(params)})
                        )
                        try:
                            import json as _json
                            result_text = _json.dumps(result, ensure_ascii=False)
                        except Exception:
                            result_text = str(result)

                        flow_state[save_as] = result
                        formatted = result_text
                        if append_to_output:
                            flow_state['last_output'] = flow_state.get('last_output', '') + "\n" + result_text

                        # è¾“å‡ºå·¥å…·ç»“æœ
                        yield StreamChunk(
                            chunk_id=str(uuid.uuid4()),
                            session_id=(context or {}).get('session_id', ''),
                            type="tool_result",
                            content=formatted,
                            metadata={"tool_name": f"{actual_server}_{actual_tool}"},
                            agent_name=self.name
                        )
                    except Exception as e:
                        yield StreamChunk(
                            chunk_id=str(uuid.uuid4()),
                            session_id=(context or {}).get('session_id', ''),
                            type="tool_error",
                            content=f"å·¥å…·èŠ‚ç‚¹æ‰§è¡Œå¤±è´¥: {str(e)}",
                            agent_name=self.name
                        )
                    nexts = node.connections or []
                    current_id = nexts[0] if nexts else None
                    continue

                if node.type == NodeType.CONDITION:
                    # å¤ç”¨ç°æœ‰å®ç°ï¼Œä¸è¾“å‡ºå†…å®¹ï¼Œä»…å†³å®šè·¯çº¿
                    cond_msg = await self._execute_condition_node(node, user_id, message, context)
                    # ç®€å•è§£æ true/false
                    text = (cond_msg.content or '').strip().lower()
                    is_true = ('true' in text) and ('false' not in text)
                    nexts = node.connections or []
                    if is_true and nexts:
                        current_id = nexts[0]
                    elif len(nexts) > 1:
                        current_id = nexts[1]
                    else:
                        current_id = None
                    continue

                if node.type == NodeType.AGENT:
                    # è°ƒç”¨ç›®æ ‡æ™ºèƒ½ä½“ï¼ˆéæµå¼ï¼‰ï¼Œæ•´ä½“ä½œä¸ºä¸€æ®µå†…å®¹è¾“å‡º
                    agent_resp = await self._execute_agent_node(node, user_id, message, context)
                    flow_state['last_output'] = flow_state.get('last_output', '') + (agent_resp.content or '')
                    yield StreamChunk(
                        chunk_id=str(uuid.uuid4()),
                        session_id=(context or {}).get('session_id', ''),
                        type="content",
                        content=agent_resp.content or '',
                        agent_name=self.name
                    )
                    nexts = node.connections or []
                    current_id = nexts[0] if nexts else None
                    continue

                # æœªçŸ¥èŠ‚ç‚¹ï¼Œç»“æŸ
                break

            # æœ€ç»ˆè¾“å‡º
            yield StreamChunk(
                chunk_id=str(uuid.uuid4()),
                session_id=(context or {}).get('session_id', ''),
                type="final",
                content=flow_state.get('last_output', ''),
                agent_name=self.name,
                metadata={},
                is_end=True
            )
        except Exception as e:
            logger.error(f"æµå¼å¤„ç†æ¶ˆæ¯å¤±è´¥: {str(e)}")
            yield StreamChunk(
                chunk_id=str(uuid.uuid4()),
                session_id=(context or {}).get('session_id', ''),
                type="error",
                content=f"å¤„ç†æ¶ˆæ¯æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}",
                agent_name=self.name,
                metadata={'error': str(e)},
                is_end=True
            ) 