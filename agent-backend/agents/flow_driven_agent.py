from typing import Dict, Any, AsyncGenerator, List, Optional
from agents.base_agent import BaseAgent
from models.chat_models import AgentMessage, StreamChunk, MessageType, AgentContext
from utils.log_helper import get_logger
from utils.llm_helper import get_llm_helper
import asyncio
import json
import uuid
from enum import Enum

logger = get_logger("flow_driven_agent")

class NodeType(str, Enum):
	"""èŠ‚ç‚¹ç±»å‹æšä¸¾"""
	AGENT = "agent"           # æ™ºèƒ½ä½“èŠ‚ç‚¹
	CONDITION = "condition"    # æ¡ä»¶èŠ‚ç‚¹
	ACTION = "action"         # åŠ¨ä½œèŠ‚ç‚¹
	LLM = "llm"               # LLM è°ƒç”¨èŠ‚ç‚¹
	TOOL = "tool"             # å·¥å…·è°ƒç”¨èŠ‚ç‚¹
	JUDGE = "judge"           # åˆ¤æ–­èŠ‚ç‚¹ï¼ˆç”¨äºåˆ¤æ–­æ˜¯å¦å¯ä»¥ç›´æ¥å›ç­”ç­‰ï¼‰
	ROUTER = "router"         # è·¯ç”±èŠ‚ç‚¹ï¼ˆç»Ÿä¸€çš„è·¯ç”±é€»è¾‘å¤„ç†ï¼‰

class FlowNode:
	"""æµç¨‹å›¾èŠ‚ç‚¹"""
	def __init__(self, node_id: str, node_type: NodeType, name: str, config: Dict[str, Any] = None):
		self.id = node_id
		self.type = node_type
		self.name = name
		self.config = config or {}
		self.position = self.config.get('position', {'x': 0, 'y': 0})
		self.connections = self.config.get('connections', [])  # è¿æ¥åˆ°çš„å…¶ä»–èŠ‚ç‚¹IDåˆ—è¡¨

class FlowDrivenAgent(BaseAgent):
	"""æµç¨‹å›¾é©±åŠ¨æ™ºèƒ½ä½“
	
	é€šè¿‡åœ¨çº¿ç¼–è¾‘æµç¨‹å›¾çš„å½¢å¼ï¼Œå°†å…¶ä»–åŸºç¡€æ™ºèƒ½ä½“ä½œä¸ºèŠ‚ç‚¹åˆ›å»ºå¤æ‚çš„å¤šæ™ºèƒ½ä½“ç»„åˆã€‚
	æ”¯æŒæ¡ä»¶åˆ†æ”¯ã€å¾ªç¯ã€å¹¶è¡Œæ‰§è¡Œç­‰å¤æ‚çš„æµç¨‹æ§åˆ¶ã€‚
	"""
	
	def __init__(self, name: str, description: str, flow_config: Dict[str, Any] = None):
		super().__init__(name, description)
		
		# æµç¨‹å›¾é…ç½®
		self.flow_config = flow_config or {}
		self.nodes = {}  # èŠ‚ç‚¹å­—å…¸ {node_id: FlowNode}
		self.start_node_id = None  # èµ·å§‹èŠ‚ç‚¹ID
		self.bound_tools: List[Any] = []  # ç»‘å®šå·¥å…·ï¼ˆserver_tool å­—ç¬¦ä¸²ï¼‰
		
		# åˆå§‹åŒ–LLMåŠ©æ‰‹
		try:
			self.llm_helper = get_llm_helper()
			logger.info(f"æµç¨‹å›¾é©±åŠ¨æ™ºèƒ½ä½“ {name} åˆå§‹åŒ–æˆåŠŸ")
		except Exception as e:
			logger.error(f"LLMåˆå§‹åŒ–å¤±è´¥: {str(e)}")
			raise
		
		# åŠ è½½æµç¨‹å›¾é…ç½®
		self._load_flow_config()
		# çŸ¥è¯†åº“ç»‘å®šå ä½
		self.bound_knowledge_bases: List[Dict[str, Any]] = []
		logger.info(f"æµç¨‹å›¾é©±åŠ¨æ™ºèƒ½ä½“ {name} åˆå§‹åŒ–å®Œæˆ")

	def set_knowledge_bases(self, knowledge_bases: List[Dict[str, Any]]):
		"""è®¾ç½®ç»‘å®šçš„çŸ¥è¯†åº“ï¼ˆä¸é€šç”¨æ™ºèƒ½ä½“å¯¹é½æ¥å£ï¼‰ã€‚"""
		self.bound_knowledge_bases = knowledge_bases or []
		try:
			names = [kb.get('name', 'Unknown') for kb in self.bound_knowledge_bases]
			logger.info(f"æµç¨‹å›¾æ™ºèƒ½ä½“ {self.name} ç»‘å®šçŸ¥è¯†åº“: {names}")
		except Exception:
			pass

	def _merge_json_into_flow_state(self, text: str, flow_state: Dict[str, Any]):
		"""å°è¯•ä» LLM æ–‡æœ¬ä¸­æå– JSON å¹¶åˆå¹¶åˆ° flow_state ä¸­ã€‚"""
		if not text:
			return
		try:
			_clean = text
			# å»é™¤<think>æ®µè½
			import re as _re
			_clean = _re.sub(r"<think>.*?</think>", "", _clean, flags=_re.IGNORECASE|_re.DOTALL)
			# æå–ä»£ç å—ä¸­çš„ JSON æˆ–ç›´æ¥è§£æ
			m = _re.search(r"```(?:json)?\s*({[\s\S]*?})\s*```", _clean)
			if m:
				_candidate = m.group(1)
			else:
				_candidate = _clean.strip()
			parsed = json.loads(_candidate)
			if isinstance(parsed, dict):
				for k, v in parsed.items():
					flow_state[str(k)] = v
		except Exception:
			# å¿½ç•¥è§£æå¤±è´¥
			pass

	def _load_flow_config(self):
		"""åŠ è½½æµç¨‹å›¾é…ç½®"""
		self.nodes = {}
		self.start_node_id = None
		
		try:
			if not self.flow_config:
				logger.warning("æµç¨‹å›¾é…ç½®ä¸ºç©º")
				return
			
			# è§£æèŠ‚ç‚¹é…ç½®
			nodes_config = self.flow_config.get('nodes', [])
			logger.info(f"å¼€å§‹è§£æ {len(nodes_config)} ä¸ªèŠ‚ç‚¹")
			
			for node_config in nodes_config:
				node_id = node_config.get('id')
				node_type = NodeType(node_config.get('type', 'agent'))
				node_data = node_config.get('data', {})
				node_name = node_data.get('label', '')
				
				# ä»dataä¸­æå–configï¼Œå¹¶ç¡®ä¿labelè¢«åŒ…å«
				node_config_dict = node_data.get('config', {})
				# ç¡®ä¿labelè¢«ä¿å­˜åˆ°configä¸­ï¼Œä¾›åç»­ä½¿ç”¨
				if node_name:
					node_config_dict['label'] = node_name
				
				logger.info(f"è§£æèŠ‚ç‚¹ {node_id}: type={node_type}, name={node_name}, config={node_config_dict}")
				
				node = FlowNode(node_id, node_type, node_name, node_config_dict)
				self.nodes[node_id] = node
				
				# æ£€æŸ¥æ˜¯å¦ä¸ºèµ·å§‹èŠ‚ç‚¹
				if node_data.get('isStartNode', False):
					self.start_node_id = node_id
					logger.info(f"è®¾ç½®èµ·å§‹èŠ‚ç‚¹: {node_id}")
			
			# å¦‚æœæ²¡æœ‰æ‰¾åˆ°èµ·å§‹èŠ‚ç‚¹ï¼Œä½¿ç”¨ç¬¬ä¸€ä¸ªèŠ‚ç‚¹ä½œä¸ºèµ·å§‹èŠ‚ç‚¹
			if not self.start_node_id and nodes_config:
				self.start_node_id = nodes_config[0]['id']
				logger.info(f"æœªæ‰¾åˆ°èµ·å§‹èŠ‚ç‚¹ï¼Œä½¿ç”¨ç¬¬ä¸€ä¸ªèŠ‚ç‚¹ä½œä¸ºèµ·å§‹èŠ‚ç‚¹: {self.start_node_id}")
			
			# è§£æè¾¹é…ç½®ï¼Œå»ºç«‹èŠ‚ç‚¹è¿æ¥å…³ç³»
			edges_config = self.flow_config.get('edges', [])
			logger.info(f"å¼€å§‹è§£æ {len(edges_config)} æ¡è¾¹")
			
			for edge_config in edges_config:
				source_id = edge_config.get('source')
				target_id = edge_config.get('target')
				source_handle = edge_config.get('sourceHandle', '')
				
				if source_id and target_id and source_id in self.nodes:
					source_node = self.nodes[source_id]
					if not hasattr(source_node, 'connections'):
						source_node.connections = []
					
					# æ ¹æ®sourceHandleå†³å®šè¿æ¥ç±»å‹
					if source_handle == 'source-true':
						# çœŸå€¼åˆ†æ”¯ï¼Œæ”¾åœ¨ç¬¬ä¸€ä¸ªä½ç½®
						if len(source_node.connections) == 0:
							source_node.connections = [target_id, None]
						else:
							source_node.connections[0] = target_id
					elif source_handle == 'source-false':
						# å‡å€¼åˆ†æ”¯ï¼Œæ”¾åœ¨ç¬¬äºŒä¸ªä½ç½®
						if len(source_node.connections) == 0:
							source_node.connections = [None, target_id]
						elif len(source_node.connections) == 1:
							source_node.connections.append(target_id)
						else:
							source_node.connections[1] = target_id
					else:
						# é»˜è®¤è¿æ¥ï¼Œæ”¾åœ¨ç¬¬ä¸€ä¸ªä½ç½®
						if len(source_node.connections) == 0:
							source_node.connections = [target_id]
						else:
							source_node.connections[0] = target_id
					
					logger.info(f"å»ºç«‹è¿æ¥: {source_id} -> {target_id} (handle: {source_handle})")
			
			logger.info(f"åŠ è½½äº† {len(self.nodes)} ä¸ªæµç¨‹å›¾èŠ‚ç‚¹")
			logger.info(f"èµ·å§‹èŠ‚ç‚¹: {self.start_node_id}")
			
			# æ‰“å°æ‰€æœ‰èŠ‚ç‚¹çš„é…ç½®å’Œè¿æ¥
			for node_id, node in self.nodes.items():
				logger.info(f"èŠ‚ç‚¹ {node_id} é…ç½®: {node.config}")
				logger.info(f"èŠ‚ç‚¹ {node_id} è¿æ¥: {getattr(node, 'connections', [])}")
		
		except Exception as e:
			logger.error(f"åŠ è½½æµç¨‹å›¾é…ç½®å¤±è´¥: {str(e)}")

	def _get_flow_state(self, context: Optional[Dict[str, Any]]) -> Dict[str, Any]:
		"""ä»ä¸Šä¸‹æ–‡è·å–/åˆå§‹åŒ–æµç¨‹çŠ¶æ€å®¹å™¨ã€‚"""
		if context is None:
			context = {}
		state = context.get('flow_state')
		if state is None:
			state = {}
			context['flow_state'] = state
		return state

	def _render_template_value(self, value: Any, variables: Dict[str, Any]) -> Any:
		"""æ¸²æŸ“å­—ç¬¦ä¸²ä¸­çš„ {{var}} æ¨¡æ¿ï¼›å¯¹ dict/list é€’å½’å¤„ç†ã€‚"""
		if isinstance(value, str):
			result = value
			for k, v in variables.items():
				placeholder = f"{{{{{k}}}}}"
				try:
					result = result.replace(placeholder, str(v))
				except Exception:
					pass
			return result
		if isinstance(value, dict):
			return {k: self._render_template_value(v, variables) for k, v in value.items()}
		if isinstance(value, list):
			return [self._render_template_value(v, variables) for v in value]
		return value

	async def _execute_llm_node(self, node: FlowNode, user_id: str, message: str, context: Dict[str, Any]) -> AgentMessage:
		"""æ‰§è¡Œ LLM èŠ‚ç‚¹ã€‚"""
		flow_state = self._get_flow_state(context)
		variables = {**flow_state, 'message': message}
		system_prompt = self._render_template_value(node.config.get('system_prompt', ''), variables)
		user_prompt = self._render_template_value(node.config.get('user_prompt', message), variables)
		save_as = node.config.get('save_as', 'last_output')
		
		logger.info(f"LLMèŠ‚ç‚¹ {node.id} å¼€å§‹æ‰§è¡Œ")
		try:
			if system_prompt:
				content = await self.llm_helper.call(messages=[
					{"role": "system", "content": system_prompt},
					{"role": "user", "content": user_prompt}
				])
			else:
				content = await self.llm_helper.call(messages=[
					{"role": "user", "content": user_prompt}
				])
			flow_state[save_as] = content
			flow_state['last_output'] = content
			# è§£æ JSON åˆå¹¶ï¼ˆä¸ºåç»­å·¥å…·èŠ‚ç‚¹æä¾› selected_* ç­‰å˜é‡ï¼‰
			self._merge_json_into_flow_state(content, flow_state)
			logger.info(f"LLMèŠ‚ç‚¹ {node.id} æ‰§è¡Œå®Œæˆï¼Œä¿å­˜ä¸º {save_as}")
		except Exception as e:
			logger.error(f"LLMèŠ‚ç‚¹æ‰§è¡Œå¤±è´¥: {str(e)}")
			content = f"LLMèŠ‚ç‚¹æ‰§è¡Œå¤±è´¥: {str(e)}"
			flow_state[save_as] = content
			flow_state['last_output'] = content
		
		# è¿”å›å½“å‰èŠ‚ç‚¹ç»“æœï¼ˆè·¯ç”±ç”±å¤–å±‚æ§åˆ¶ï¼‰
		return AgentMessage(
			id=str(uuid.uuid4()),
			type=MessageType.AGENT,
			content=flow_state['last_output'],
			agent_name=self.name,
			metadata={'node_id': node.id, 'node_type': node.type.value}
		)

	async def _select_bound_tool(self, desired_server: Optional[str], desired_tool: Optional[str], mcp_helper) -> Optional[tuple[str, str]]:
		available_services = await mcp_helper.get_available_services()
		if not getattr(self, 'bound_tools', None):
			return None
		# æ„å»ºå€™é€‰ï¼ˆä»…ä¿ç•™å¯ç”¨æœåŠ¡ï¼‰
		candidates: List[tuple[str, str]] = []
		for item in self.bound_tools:
			val = str(item)
			if '_' in val:
				s, t = val.split('_', 1)
				if not available_services or s in available_services:
					candidates.append((s, t))
		# æ‰“åˆ†æ’åº
		def score(pair: tuple[str, str]) -> int:
			s, t = pair
			score = 0
			if desired_server and s == desired_server:
				score += 2
			if desired_tool and (t == desired_tool or t.endswith(desired_tool)):
				score += 3
			return score
		candidates.sort(key=score, reverse=True)
		# éªŒè¯å·¥å…·å­˜åœ¨
		for s, t in candidates:
			if not desired_tool:
				return (s, t)
			if await self._server_has_tool(mcp_helper, s, t):
				return (s, t)
		return candidates[0] if candidates else None

	async def _find_tool_in_services(self, desired_tool: Optional[str], mcp_helper) -> Optional[tuple[str, str]]:
		if not desired_tool:
			return None
		services = await mcp_helper.get_available_services()
		for s in services:
			try:
				tools = await mcp_helper.get_tools(server_name=s)
				for tk in tools:
					name = tk.get('name') if isinstance(tk, dict) else getattr(tk, 'name', '')
					if name == desired_tool or name.endswith(desired_tool):
						return (s, name)
			except Exception:
				continue
		return None

	async def _execute_tool_node(self, node: FlowNode, user_id: str, message: str, context: Dict[str, Any]) -> AgentMessage:
		"""æ‰§è¡Œå·¥å…·èŠ‚ç‚¹ã€‚æ”¯æŒ server_tool åˆå¹¶æ ¼å¼ä¸å˜é‡æ¨¡æ¿ã€‚"""
		flow_state = self._get_flow_state(context)
		variables = {**flow_state, 'message': message}
		server = self._render_template_value(node.config.get('server'), variables)
		tool = self._render_template_value(node.config.get('tool'), variables)
		params = self._render_template_value(node.config.get('params', {}), variables)
		save_as = node.config.get('save_as', 'last_output')
		
		logger.info(f"å·¥å…·èŠ‚ç‚¹ {node.id} è°ƒç”¨: {server}.{tool} å‚æ•°: {params}")
		try:
			from main import agent_manager
			if not agent_manager or not getattr(agent_manager, 'mcp_helper', None):
				raise RuntimeError("MCPåŠ©æ‰‹æœªåˆå§‹åŒ–")
			mcp_helper = agent_manager.mcp_helper
			
			actual_server = server
			actual_tool = tool
			if tool and '_' in tool and not server:
				parts = tool.split('_', 1)
				actual_server = parts[0]
				actual_tool = parts[1]
			
			# ä¼˜å…ˆé€‰æ‹©ç»‘å®šå·¥å…·ï¼Œè‹¥æœªæŒ‡å®šæˆ–ä¸å¯ç”¨åˆ™å›é€€
			selected = await self._select_bound_tool(actual_server, actual_tool, mcp_helper)
			if selected:
				actual_server, actual_tool = selected
			else:
				# è‹¥æœªåŒ¹é…ä¸Šç»‘å®šå·¥å…·ï¼Œä½†æŒ‡å®šäº† toolï¼Œå°è¯•è·¨æœåŠ¡æŸ¥æ‰¾
				found = await self._find_tool_in_services(actual_tool, mcp_helper)
				if found:
					actual_server, actual_tool = found
				else:
					# æœ€åå›é€€ï¼šä»»é€‰ä¸€ä¸ªå¯ç”¨æœåŠ¡ï¼ˆå¯èƒ½å¤±è´¥ï¼Œä½†å°½åŠ›è€Œä¸ºï¼‰
					services = await mcp_helper.get_available_services()
					if services and not actual_server:
						actual_server = services[0]
			
			if not actual_server or not actual_tool:
				raise RuntimeError("æœªèƒ½è§£æå¯ç”¨çš„ server/tool")
			
			# è°ƒç”¨å·¥å…·
			result = await mcp_helper.call_tool(
				server_name=actual_server,
				tool_name=actual_tool,
				**(params if isinstance(params, dict) else {"query": str(params)})
			)
			try:
				result_text = json.dumps(result, ensure_ascii=False)
			except Exception:
				result_text = str(result)
			flow_state[save_as] = result
			flow_state['last_output'] = result_text
			return AgentMessage(
				id=str(uuid.uuid4()),
				type=MessageType.AGENT,
				content=result_text,
				agent_name=self.name,
				metadata={'node_id': node.id, 'node_type': node.type.value, 'tool': f"{actual_server}_{actual_tool}"}
			)
		except Exception as e:
			logger.error(f"å·¥å…·èŠ‚ç‚¹æ‰§è¡Œå¤±è´¥: {str(e)}")
			raise

	async def _execute_agent_node(self, node: FlowNode, user_id: str, message: str, context: Dict[str, Any]) -> AgentMessage:
		"""æ‰§è¡Œæ™ºèƒ½ä½“èŠ‚ç‚¹"""
		agent_name = node.config.get('agent_name')
		if not agent_name:
			raise ValueError(f"æ™ºèƒ½ä½“èŠ‚ç‚¹ {node.id} æœªé…ç½®æ™ºèƒ½ä½“åç§°")
		
		try:
			# å°è¯•ä»AgentManagerè·å–å¯¹åº”çš„æ™ºèƒ½ä½“
			from main import agent_manager
			if agent_manager and agent_name in agent_manager.agents:
				# ä½¿ç”¨å®é™…çš„æ™ºèƒ½ä½“
				target_agent = agent_manager.agents[agent_name]
				response = await target_agent.process_message(user_id, message, context)
				return response
			else:
				# å¦‚æœæ‰¾ä¸åˆ°æ™ºèƒ½ä½“ï¼Œä½¿ç”¨LLMæ¨¡æ‹Ÿ
				prompt = f"ä½œä¸ºæ™ºèƒ½ä½“ '{agent_name}'ï¼Œè¯·å¤„ç†ä»¥ä¸‹ç”¨æˆ·æ¶ˆæ¯ï¼š\n{message}"
				response = await self.llm_helper.call(
					messages=[{"role": "user", "content": prompt}]
				)
				
				return AgentMessage(
					id=str(uuid.uuid4()),
					type=MessageType.AGENT,
					content=response,
					agent_name=f"{self.name}->{agent_name}",
					metadata={'node_id': node.id, 'node_type': node.type.value, 'agent_name': agent_name}
				)
		except Exception as e:
			logger.error(f"æ‰§è¡Œæ™ºèƒ½ä½“èŠ‚ç‚¹å¤±è´¥: {str(e)}")
			raise
	
	def _select_tool_from_bound(self, desired_server: Optional[str], desired_tool: Optional[str], mcp_helper) -> Optional[tuple[str, str]]:
		"""ä»ç»‘å®šå·¥å…·åˆ—è¡¨ä¸­é€‰æ‹©æœ€åˆé€‚çš„ (server, tool)ã€‚
		ä¼˜å…ˆåŒ¹é…ï¼šserver+tool å…¨åŒ¹é… > tool ååŒ¹é… > server åŒ¹é… > é¦–ä¸ªç»‘å®šã€‚
		å¹¶éªŒè¯è¯¥ server/tool åœ¨å¯ç”¨åˆ—è¡¨ä¸­å­˜åœ¨ã€‚
		"""
		if not getattr(self, 'bound_tools', None):
			return None
		candidates: List[tuple[str, str]] = []
		for item in self.bound_tools:
			val = str(item)
			if '_' in val:
				s, t = val.split('_', 1)
				candidates.append((s, t))
		# æ’åºæ‰“åˆ†
		def score(pair: tuple[str, str]) -> int:
			s, t = pair
			score = 0
			if desired_server and s == desired_server:
				score += 2
			if desired_tool and (t == desired_tool or t.endswith(desired_tool)):
				score += 3
			return score
		candidates.sort(key=score, reverse=True)
		# éªŒè¯å¯ç”¨æ€§ï¼ˆæœåŠ¡å­˜åœ¨ä¸”å·¥å…·å­˜åœ¨ï¼‰
		return self._first_valid_tool(candidates, mcp_helper)

	async def _server_has_tool(self, mcp_helper, server: str, tool: str) -> bool:
		try:
			tools = await mcp_helper.get_tools(server_name=server)
			for tk in tools:
				name = tk.get('name') if isinstance(tk, dict) else getattr(tk, 'name', '')
				if name == tool:
					return True
		except Exception:
			return False
		return False

	def _first_valid_tool(self, pairs: List[tuple[str, str]], mcp_helper) -> Optional[tuple[str, str]]:
		# ä»…éªŒè¯æœåŠ¡å­˜åœ¨ï¼Œå·¥å…·å­˜åœ¨æ€§åœ¨è°ƒç”¨å‰å†æ£€æŸ¥ä»¥èŠ‚çœè¯·æ±‚
		return pairs[0] if pairs else None

	async def _execute_condition_node(self, node: FlowNode, user_id: str, message: str, context: Dict[str, Any]) -> AgentMessage:
		"""æ‰§è¡Œæ¡ä»¶èŠ‚ç‚¹ï¼Œä»…è¿”å› true/false æ–‡æœ¬ï¼Œä¸åšè·¯ç”±ã€‚"""
		condition = node.config.get('condition', '')
		if not condition:
			raise ValueError(f"æ¡ä»¶èŠ‚ç‚¹ {node.id} æœªé…ç½®æ¡ä»¶")
		flow_state = self._get_flow_state(context)
		variables = {**flow_state, 'message': message}
		rendered_condition = self._render_template_value(condition, variables)
		prompt = (
			"è¯·åŸºäºä»¥ä¸‹ä¿¡æ¯åˆ¤æ–­æ¡ä»¶æ˜¯å¦æˆç«‹ï¼Œä¸¥æ ¼åªå›ç­” true æˆ– falseã€‚\n"
			f"æ¡ä»¶ï¼š{rendered_condition}\n"
			f"ç”¨æˆ·æ¶ˆæ¯ï¼š{message}\n"
			f"æµç¨‹çŠ¶æ€ï¼ˆJSONï¼‰ï¼š{json.dumps(flow_state, ensure_ascii=False)}\n"
		)
		try:
			response = await self.llm_helper.call(messages=[{"role": "user", "content": prompt}])
			text = (response or '').strip().lower()
			is_true = ('true' in text) and ('false' not in text)
			return AgentMessage(
				id=str(uuid.uuid4()),
				type=MessageType.AGENT,
				content='true' if is_true else 'false',
				agent_name=self.name,
				metadata={'node_id': node.id, 'node_type': node.type.value}
			)
		except Exception as e:
			logger.error(f"æ‰§è¡Œæ¡ä»¶èŠ‚ç‚¹å¤±è´¥: {str(e)}")
			raise
	
	async def _execute_action_node(self, node: FlowNode, user_id: str, message: str, context: Dict[str, Any]) -> AgentMessage:
		"""æ‰§è¡ŒåŠ¨ä½œèŠ‚ç‚¹"""
		action = node.config.get('action', '')
		if not action:
			raise ValueError(f"åŠ¨ä½œèŠ‚ç‚¹ {node.id} æœªé…ç½®åŠ¨ä½œ")
		
		# æ‰§è¡ŒåŠ¨ä½œï¼ˆè¿™é‡Œå¯ä»¥æ‰©å±•ä¸ºè°ƒç”¨å…·ä½“çš„å·¥å…·æˆ–APIï¼‰
		result = f"æ‰§è¡ŒåŠ¨ä½œï¼š{action}"
		
		# å¦‚æœæœ‰åç»­èŠ‚ç‚¹ï¼Œç»§ç»­æ‰§è¡Œ
		if node.connections:
			next_node_id = node.connections[0]
			return await self._execute_node(next_node_id, user_id, message, context)
		else:
			return AgentMessage(
				id=str(uuid.uuid4()),
				type=MessageType.AGENT,
				content=result,
				agent_name=self.name,
				metadata={'node_id': node.id, 'node_type': node.type.value, 'action': action}
			)

	async def _execute_judge_node(self, node: FlowNode, user_id: str, message: str, context: Dict[str, Any]) -> AgentMessage:
		"""æ‰§è¡Œåˆ¤æ–­èŠ‚ç‚¹"""
		judge_type = node.config.get('judge_type', 'custom')
		flow_state = self._get_flow_state(context)
		variables = {**flow_state, 'message': message}
		
		# è·å–é…ç½®çš„æç¤ºè¯
		system_prompt = self._render_template_value(
			node.config.get('system_prompt', 
				"ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½åˆ¤æ–­å™¨ï¼Œè¯·æ ¹æ®ç”¨æˆ·è¾“å…¥å’Œä¸Šä¸‹æ–‡è¿›è¡Œåˆ¤æ–­ã€‚"
			), 
			variables
		)
		user_prompt = self._render_template_value(
			node.config.get('user_prompt', 
				"è¯·æ ¹æ®ä»¥ä¸‹ä¿¡æ¯è¿›è¡Œåˆ¤æ–­ï¼Œå¹¶è¾“å‡ºJSONæ ¼å¼çš„ç»“æœã€‚\n\nç”¨æˆ·è¾“å…¥ï¼š{{message}}\n\nè¯·è¾“å‡ºåˆ¤æ–­ç»“æœï¼š"
			), 
			variables
		)
		
		# æ ¹æ®åˆ¤æ–­ç±»å‹è®¾ç½®ä¸åŒçš„é»˜è®¤æç¤ºè¯
		if judge_type == 'direct_answer':
			system_prompt = self._render_template_value(
				node.config.get('system_prompt', 
					"ä½ æ˜¯ä¸€ä¸ªåˆ¤æ–­å™¨ã€‚ç»™å®šç”¨æˆ·é—®é¢˜ï¼Œåˆ¤æ–­æ˜¯å¦å¯ä»¥åœ¨ä¸æŸ¥è¯¢å¤–éƒ¨æ•°æ®ã€å·¥å…·æˆ–çŸ¥è¯†åº“çš„å‰æä¸‹ç»™å‡ºå¯é å›ç­”ã€‚"
				), 
				variables
			)
			user_prompt = self._render_template_value(
				node.config.get('user_prompt', 
					"ä¸¥æ ¼è¾“å‡ºJSONï¼š{\"can_direct_answer\": true|false, \"answer\": string}ã€‚\nç”¨æˆ·é—®é¢˜ï¼š{{message}}"
				), 
				variables
			)
		elif judge_type == 'domain_classification':
			system_prompt = self._render_template_value(
				node.config.get('system_prompt', 
					"ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„é—®é¢˜åˆ†ç±»å™¨ï¼Œè¯·åˆ¤æ–­ç”¨æˆ·é—®é¢˜å±äºå“ªä¸ªé¢†åŸŸã€‚"
				), 
				variables
			)
			user_prompt = self._render_template_value(
				node.config.get('user_prompt', 
					"è¯·è¾“å‡ºJSONï¼š{\"domain\": \"æŠ€æœ¯|ç”Ÿæ´»|å·¥ä½œ|å…¶ä»–\", \"can_handle\": true|false, \"reason\": \"åˆ†ç±»åŸå› \"}"
				), 
				variables
			)
		elif judge_type == 'tool_selection':
			system_prompt = self._render_template_value(
				node.config.get('system_prompt', 
					"ä½ æ˜¯ä¸€ä¸ªå·¥å…·é€‰æ‹©å™¨ï¼Œè¯·æ ¹æ®ç”¨æˆ·é—®é¢˜é€‰æ‹©æœ€åˆé€‚çš„å·¥å…·ã€‚"
				), 
				variables
			)
			user_prompt = self._render_template_value(
				node.config.get('user_prompt', 
					"è¯·è¾“å‡ºJSONï¼š{\"selected_tool\": \"å·¥å…·å\", \"confidence\": 0.0-1.0, \"reason\": \"é€‰æ‹©åŸå› \"}"
				), 
				variables
			)
		elif judge_type == 'intent_recognition':
			system_prompt = self._render_template_value(
				node.config.get('system_prompt', 
					"ä½ æ˜¯ä¸€ä¸ªæ„å›¾è¯†åˆ«å™¨ï¼Œè¯·è¯†åˆ«ç”¨æˆ·çš„çœŸå®æ„å›¾ã€‚"
				), 
				variables
			)
			user_prompt = self._render_template_value(
				node.config.get('user_prompt', 
					"è¯·è¾“å‡ºJSONï¼š{\"intent\": \"æŸ¥è¯¢|æ“ä½œ|å»ºè®®|å…¶ä»–\", \"priority\": \"high|medium|low\", \"requires_tool\": true|false}"
				), 
				variables
			)
		elif judge_type == 'custom':
			# ä½¿ç”¨ç”¨æˆ·è‡ªå®šä¹‰çš„æç¤ºè¯
			pass
		
		try:
			response = await self.llm_helper.call(messages=[
				{"role": "system", "content": system_prompt},
				{"role": "user", "content": user_prompt}
			])
			
			# å°è¯•è§£æJSON
			parsed = None
			try:
				parsed = json.loads(response)
			except Exception:
				parsed = None
			
			# ä¿å­˜åˆ¤æ–­ç»“æœåˆ°æµç¨‹çŠ¶æ€
			save_as = node.config.get('save_as', 'judge_result')
			flow_state[save_as] = parsed or response
			flow_state['last_output'] = response
			
			# æ ¹æ®åˆ¤æ–­ç±»å‹è®¾ç½®ä¸åŒçš„æµç¨‹çŠ¶æ€å˜é‡
			if parsed and isinstance(parsed, dict):
				if judge_type == 'direct_answer':
					flow_state['judge_can_direct_answer'] = parsed.get('can_direct_answer', False)
					flow_state['judge_answer'] = parsed.get('answer', '')
				elif judge_type == 'domain_classification':
					flow_state['judge_domain'] = parsed.get('domain', '')
					flow_state['judge_can_handle'] = parsed.get('can_handle', False)
				elif judge_type == 'tool_selection':
					flow_state['judge_selected_tool'] = parsed.get('selected_tool', '')
					flow_state['judge_confidence'] = parsed.get('confidence', 0.0)
				elif judge_type == 'intent_recognition':
					flow_state['judge_intent'] = parsed.get('intent', '')
					flow_state['judge_priority'] = parsed.get('priority', 'medium')
					flow_state['judge_requires_tool'] = parsed.get('requires_tool', False)
			
			return AgentMessage(
				id=str(uuid.uuid4()),
				type=MessageType.AGENT,
				content=response,
				agent_name=self.name,
				metadata={'node_id': node.id, 'node_type': node.type.value, 'judge_type': judge_type}
			)
		except Exception as e:
			logger.error(f"æ‰§è¡Œåˆ¤æ–­èŠ‚ç‚¹å¤±è´¥: {str(e)}")
			raise

	async def _execute_router_node(self, node: FlowNode, user_id: str, message: str, context: Dict[str, Any]) -> AgentMessage:
		"""æ‰§è¡Œè·¯ç”±èŠ‚ç‚¹ - ç»Ÿä¸€çš„è·¯ç”±é€»è¾‘å¤„ç†"""
		flow_state = self._get_flow_state(context)
		routing_config = node.config.get('routing_logic', {})
		
		if not routing_config:
			raise ValueError(f"è·¯ç”±èŠ‚ç‚¹ {node.id} æœªé…ç½®è·¯ç”±é€»è¾‘")
		
		# è·å–è·¯ç”±å­—æ®µå’Œå€¼
		field = routing_config.get('field', '')
		value = routing_config.get('value', None)
		true_branch = routing_config.get('true_branch', '')
		false_branch = routing_config.get('false_branch', '')
		
		if not field:
			raise ValueError(f"è·¯ç”±èŠ‚ç‚¹ {node.id} æœªé…ç½®è·¯ç”±å­—æ®µ")
		
		# ä»æµç¨‹çŠ¶æ€è·å–å­—æ®µå€¼
		field_value = flow_state.get(field)
		
		# æ ¹æ®è·¯ç”±é€»è¾‘é€‰æ‹©åˆ†æ”¯
		selected_branch = None
		if value is not None:
			# ç²¾ç¡®å€¼åŒ¹é…
			if field_value == value:
				selected_branch = 'true'
			else:
				selected_branch = 'false'
		else:
			# å¸ƒå°”å€¼åˆ¤æ–­
			if isinstance(field_value, bool):
				selected_branch = 'true' if field_value else 'false'
			elif isinstance(field_value, (int, float)):
				# æ•°å€¼åˆ¤æ–­
				threshold = routing_config.get('threshold', 0)
				operator = routing_config.get('operator', '>')
				
				if operator == '>':
					selected_branch = 'true' if field_value > threshold else 'false'
				elif operator == '>=':
					selected_branch = 'true' if field_value >= threshold else 'false'
				elif operator == '<':
					selected_branch = 'true' if field_value < threshold else 'false'
				elif operator == '<=':
					selected_branch = 'true' if field_value <= threshold else 'false'
				elif operator == '==':
					selected_branch = 'true' if field_value == threshold else 'false'
				else:
					selected_branch = 'false'
			elif isinstance(field_value, str):
				# å­—ç¬¦ä¸²åˆ¤æ–­
				pattern = routing_config.get('pattern', '')
				if pattern:
					import re
					if re.search(pattern, field_value):
						selected_branch = 'true'
					else:
						selected_branch = 'false'
				else:
					# éç©ºå­—ç¬¦ä¸²åˆ¤æ–­
					selected_branch = 'true' if field_value else 'false'
			else:
				# å…¶ä»–ç±»å‹ï¼Œé»˜è®¤ä¸ºfalse
				selected_branch = 'false'
		
		# è®°å½•è·¯ç”±å†³ç­–
		logger.info(f"è·¯ç”±èŠ‚ç‚¹ {node.id} å­—æ®µ {field}={field_value}, é€‰æ‹©åˆ†æ”¯: {selected_branch}")
		logger.info(f"è·¯ç”±èŠ‚ç‚¹ {node.id} å¯ç”¨åˆ†æ”¯: {true_branch} (çœŸå€¼), {false_branch} (å‡å€¼)")
		
		# å°†è·¯ç”±å†³ç­–ä¿å­˜åˆ°æµç¨‹çŠ¶æ€ï¼Œä¾›åç»­èŠ‚ç‚¹ä½¿ç”¨
		flow_state['router_decision'] = {
			'field': field,
			'value': field_value,
			'selected_branch': selected_branch,
			'timestamp': str(uuid.uuid4())
		}
		
		return AgentMessage(
			id=str(uuid.uuid4()),
			type=MessageType.AGENT,
			content=f"è·¯ç”±å†³ç­–: {field}={field_value} -> {selected_branch}",
			agent_name=self.name,
			metadata={'node_id': node.id, 'node_type': node.type.value, 'selected_branch': selected_branch}
		)
	
	async def process_message(self, user_id: str, message: str, context: Dict[str, Any] = None) -> AgentMessage:
		"""å¤„ç†ç”¨æˆ·æ¶ˆæ¯"""
		return await self.execute_flow(user_id, message, context)
	
	async def process_message_stream(self, user_id: str, message: str, context: Dict[str, Any] = None) -> AsyncGenerator[StreamChunk, None]:
		"""æµå¼å¤„ç†ç”¨æˆ·æ¶ˆæ¯ï¼šæŒ‰èŠ‚ç‚¹æ‰§è¡Œå¹¶é€æ­¥è¾“å‡ºã€‚
		- LLM èŠ‚ç‚¹ï¼šä½¿ç”¨ call_stream æŒ‰å—è¾“å‡º type="content"
		- TOOL èŠ‚ç‚¹ï¼šå·¥å…·æ‰§è¡Œå®Œæˆåè¾“å‡º type="tool_result"
		- å…¶ä»–èŠ‚ç‚¹ï¼šæ•´ä½“å†…å®¹ä½œä¸ºä¸€æ®µ type="content"
		- æœ€ç»ˆï¼šè¾“å‡º type="final"
		"""
		try:
			flow_state = self._get_flow_state(context)
			base_vars = {"message": message}
			
			# æ·»åŠ è°ƒè¯•æ—¥å¿—
			logger.info(f"ğŸš€ å¼€å§‹æ‰§è¡Œæµç¨‹å›¾ï¼Œèµ·å§‹èŠ‚ç‚¹: {self.start_node_id}")
			logger.info(f"ğŸš€ æµç¨‹å›¾èŠ‚ç‚¹æ•°é‡: {len(self.nodes)}")
			logger.info(f"ğŸš€ æµç¨‹å›¾èŠ‚ç‚¹ç±»å‹: {[node.type.value for node in self.nodes.values()]}")
			logger.info(f"ğŸš€ æµç¨‹å›¾èŠ‚ç‚¹è¯¦æƒ…: {[(node.id, node.type.value, node.name) for node in self.nodes.values()]}")
			logger.info(f"ğŸš€ ç”¨æˆ·æ¶ˆæ¯: {message}")
			logger.info(f"ğŸš€ æµç¨‹çŠ¶æ€: {flow_state}")
			
			if not self.start_node_id:
				yield StreamChunk(
					chunk_id=str(uuid.uuid4()),
					session_id=(context or {}).get('session_id', ''),
					type="error",
					content="æµç¨‹å›¾æœªé…ç½®èµ·å§‹èŠ‚ç‚¹ï¼Œæ— æ³•æ‰§è¡Œã€‚",
					agent_name=self.name,
					metadata={'flow_executed': False, 'error': 'no_start_node'},
					is_end=True
				)
				return

			current_id = self.start_node_id
			step_guard = 0

			while current_id and step_guard < 1000:
				step_guard += 1
				node = self.nodes.get(current_id)
				if not node:
					logger.error(f"ğŸš¨ æ‰¾ä¸åˆ°èŠ‚ç‚¹: {current_id}")
					break

				logger.info(f"ğŸš€ æ‰§è¡ŒèŠ‚ç‚¹ {step_guard}: {current_id} ({node.type.value}) - {node.name}")
				vars_all = {**flow_state, **base_vars}

				if node.type == NodeType.LLM:
					logger.info(f"ğŸš€ è¿›å…¥LLMèŠ‚ç‚¹å¤„ç†åˆ†æ”¯: {current_id}")
					# å‘é€èŠ‚ç‚¹å¼€å§‹æ ‡è¯†
					logger.info(f"ğŸš€ å‡†å¤‡å‘é€èŠ‚ç‚¹å¼€å§‹äº‹ä»¶: {node.id} ({node.name})")
					logger.info(f"ğŸš€ èŠ‚ç‚¹metadata: node_id={node.id}, node_type={node.type.value}, node_name={node.name}, node_label={node.config.get('label', node.name)}")
					
					# æ·»åŠ è°ƒè¯•æ—¥å¿—ï¼Œç¡®è®¤å³å°†å‘é€node_startäº‹ä»¶
					logger.info(f"ğŸš€ å³å°†å‘é€StreamChunk: type=node_start, content=ğŸš€ å¼€å§‹æ‰§è¡Œ {node.name} èŠ‚ç‚¹")
					
					yield StreamChunk(
						chunk_id=str(uuid.uuid4()),
						session_id=(context or {}).get('session_id', ''),
						type="node_start",
						content=f"ğŸš€ å¼€å§‹æ‰§è¡Œ {node.name} èŠ‚ç‚¹",
						agent_name=self.name,
						metadata={
							'node_id': node.id,
							'node_type': node.type.value,
							'node_name': node.name,
							'node_label': node.config.get('label', node.name)
						}
					)
					
					logger.info(f"ğŸš€ èŠ‚ç‚¹å¼€å§‹äº‹ä»¶å·²å‘é€: {node.id}")
					logger.info(f"ğŸš€ èŠ‚ç‚¹å¼€å§‹äº‹ä»¶å‘é€å®Œæˆï¼Œç»§ç»­æ‰§è¡ŒLLMé€»è¾‘")
					
					# æ¸²æŸ“æç¤º
					system_prompt = self._render_template_value(node.config.get('system_prompt', ''), vars_all)
					user_prompt = self._render_template_value(node.config.get('user_prompt', message), vars_all)
					save_as = node.config.get('save_as', 'last_output')

					try:
						msgs = []
						if system_prompt:
							msgs.append({"role": "system", "content": system_prompt})
						msgs.append({"role": "user", "content": user_prompt})

						acc = ""
						async for piece in self.llm_helper.call_stream(messages=msgs):
							if not piece:
								continue
							acc += piece
							flow_state['last_output'] = flow_state.get('last_output', '') + piece
							# æµå¼è¾“å‡ºï¼Œæ·»åŠ èŠ‚ç‚¹æ ‡è¯†
							yield StreamChunk(
								chunk_id=str(uuid.uuid4()),
								session_id=(context or {}).get('session_id', ''),
								type="content",
								content=piece,
								agent_name=self.name,
								metadata={
									'node_id': node.id,
									'node_type': node.type.value,
									'node_name': node.name,
									'node_label': node.config.get('label', node.name)
								}
							)
						flow_state[save_as] = acc
						# å°è¯•è§£æ JSON å¹¶åˆå¹¶åˆ° flow_state
						self._merge_json_into_flow_state(acc, flow_state)
						
						# è¾“å‡ºèŠ‚ç‚¹æ‰§è¡Œå®Œæˆæ ‡è¯†
						yield StreamChunk(
							chunk_id=str(uuid.uuid4()),
							session_id=(context or {}).get('session_id', ''),
							type="node_complete",
							content=f"âœ… {node.name} èŠ‚ç‚¹æ‰§è¡Œå®Œæˆ",
							agent_name=self.name,
							metadata={
								'node_id': node.id,
								'node_type': node.type.value,
								'node_name': node.name,
								'node_label': node.config.get('label', node.name),
								'output': acc
							}
						)
					except Exception as e:
						yield StreamChunk(
							chunk_id=str(uuid.uuid4()),
							session_id=(context or {}).get('session_id', ''),
							type="error",
							content=f"LLMèŠ‚ç‚¹æ‰§è¡Œå¤±è´¥: {str(e)}",
							agent_name=self.name,
							metadata={
								'node_id': node.id,
								'node_type': node.type.value,
								'node_name': node.name
							}
						)
					# ä¸‹ä¸€ä¸ª
					nexts = node.connections or []
					current_id = nexts[0] if nexts else None
					continue

				if node.type == NodeType.TOOL:
					server = self._render_template_value(node.config.get('server'), vars_all)
					tool = self._render_template_value(node.config.get('tool'), vars_all)
					params_raw = node.config.get('params', {})
					params = self._render_template_value(params_raw, vars_all)
					save_as = node.config.get('save_as', 'last_output')
					append_to_output = node.config.get('append_to_output', True)

					try:
						from main import agent_manager
						if not agent_manager or not getattr(agent_manager, 'mcp_helper', None):
							raise RuntimeError("MCPåŠ©æ‰‹æœªåˆå§‹åŒ–")
						mcp = agent_manager.mcp_helper

						actual_server = server
						actual_tool = tool
						if tool and '_' in tool and not server:
							parts = tool.split('_', 1)
							actual_server = parts[0]
							actual_tool = parts[1]
						if not actual_server:
							services = await mcp.get_available_services()
							if not services:
								raise RuntimeError("æ²¡æœ‰å¯ç”¨çš„MCPæœåŠ¡")
							actual_server = services[0]

						result = await mcp.call_tool(
							server_name=actual_server,
							tool_name=actual_tool,
							**(params if isinstance(params, dict) else {"query": str(params)})
						)
						try:
							import json as _json
							result_text = _json.dumps(result, ensure_ascii=False)
						except Exception:
							result_text = str(result)

						flow_state[save_as] = result
						formatted = result_text
						if append_to_output:
							flow_state['last_output'] = flow_state.get('last_output', '') + "\n" + result_text

						# è¾“å‡ºå·¥å…·ç»“æœ
						yield StreamChunk(
							chunk_id=str(uuid.uuid4()),
							session_id=(context or {}).get('session_id', ''),
							type="tool_result",
							content=formatted,
							metadata={
								"tool_name": f"{actual_server}_{actual_tool}",
								'node_id': node.id,
								'node_type': node.type.value,
								'node_name': node.name,
								'node_label': node.config.get('label', node.name)
							},
							agent_name=self.name
						)
					except Exception as e:
						yield StreamChunk(
							chunk_id=str(uuid.uuid4()),
							session_id=(context or {}).get('session_id', ''),
							type="tool_error",
							content=f"å·¥å…·èŠ‚ç‚¹æ‰§è¡Œå¤±è´¥: {str(e)}",
							agent_name=self.name,
							metadata={
								'node_id': node.id,
								'node_type': node.type.value,
								'node_name': node.name,
								'node_label': node.config.get('label', node.name)
							}
						)
					nexts = node.connections or []
					current_id = nexts[0] if nexts else None
					continue

				if node.type == NodeType.CONDITION:
					# å¤ç”¨ç°æœ‰å®ç°ï¼Œä¸è¾“å‡ºå†…å®¹ï¼Œä»…å†³å®šè·¯çº¿
					cond_msg = await self._execute_condition_node(node, user_id, message, context)
					# ç®€å•è§£æ true/false
					text = (cond_msg.content or '').strip().lower()
					is_true = ('true' in text) and ('false' not in text)
					nexts = node.connections or []
					if is_true and nexts:
						current_id = nexts[0]
					elif len(nexts) > 1:
						current_id = nexts[1]
					else:
						current_id = None
					continue

				if node.type == NodeType.JUDGE:
					# æ‰§è¡Œåˆ¤æ–­èŠ‚ç‚¹
					judge_msg = await self._execute_judge_node(node, user_id, message, context)
					flow_state['last_output'] = flow_state.get('last_output', '') + (judge_msg.content or '')
					
					# è¾“å‡ºåˆ¤æ–­ç»“æœ
					yield StreamChunk(
						chunk_id=str(uuid.uuid4()),
						session_id=(context or {}).get('session_id', ''),
						type="content",
						content=judge_msg.content or '',
						agent_name=self.name,
						metadata={
							'node_id': node.id,
							'node_type': node.type.value,
							'node_name': node.name,
							'node_label': node.config.get('label', node.name),
							'judge_type': judge_type
						}
					)
					
					# æ ¹æ®åˆ¤æ–­ç±»å‹å’Œç»“æœå†³å®šä¸‹ä¸€æ­¥è·¯å¾„
					judge_type = node.config.get('judge_type', 'custom')
					nexts = node.connections or []
					
					if judge_type == 'direct_answer':
						# ç›´æ¥å›ç­”åˆ¤æ–­ï¼šæ ¹æ®can_direct_answeré€‰æ‹©åˆ†æ”¯
						can_direct_answer = flow_state.get('judge_can_direct_answer', False)
						if can_direct_answer and len(nexts) > 0:
							current_id = nexts[0]  # ç¬¬ä¸€ä¸ªåˆ†æ”¯ï¼šç›´æ¥å›ç­”
							logger.info(f"åˆ¤æ–­èŠ‚ç‚¹ {node.id} é€‰æ‹©ç›´æ¥å›ç­”åˆ†æ”¯: {current_id}")
						elif len(nexts) > 1:
							current_id = nexts[1]  # ç¬¬äºŒä¸ªåˆ†æ”¯ï¼šéœ€è¦å·¥å…·
							logger.info(f"åˆ¤æ–­èŠ‚ç‚¹ {node.id} é€‰æ‹©å·¥å…·è°ƒç”¨åˆ†æ”¯: {current_id}")
						elif len(nexts) > 0:
							current_id = nexts[0]
							logger.info(f"åˆ¤æ–­èŠ‚ç‚¹ {node.id} åªæœ‰ä¸€ä¸ªåˆ†æ”¯ï¼Œç»§ç»­æ‰§è¡Œ: {current_id}")
						else:
							current_id = None
							logger.info(f"åˆ¤æ–­èŠ‚ç‚¹ {node.id} æ²¡æœ‰åç»­èŠ‚ç‚¹ï¼Œç»“æŸæµç¨‹")
					
					elif judge_type == 'domain_classification':
						# é¢†åŸŸåˆ†ç±»åˆ¤æ–­ï¼šæ ¹æ®domainå’Œcan_handleé€‰æ‹©åˆ†æ”¯
						domain = flow_state.get('judge_domain', '')
						can_handle = flow_state.get('judge_can_handle', False)
						if can_handle and len(nexts) > 0:
							current_id = nexts[0]  # ç¬¬ä¸€ä¸ªåˆ†æ”¯ï¼šå¯ä»¥å¤„ç†
							logger.info(f"åˆ¤æ–­èŠ‚ç‚¹ {node.id} é€‰æ‹©å¯å¤„ç†åˆ†æ”¯: {current_id}")
						elif len(nexts) > 1:
							current_id = nexts[1]  # ç¬¬äºŒä¸ªåˆ†æ”¯ï¼šæ— æ³•å¤„ç†
							logger.info(f"åˆ¤æ–­èŠ‚ç‚¹ {node.id} é€‰æ‹©æ— æ³•å¤„ç†åˆ†æ”¯: {current_id}")
						elif len(nexts) > 0:
							current_id = nexts[0]
						else:
							current_id = None
					
					elif judge_type == 'tool_selection':
						# å·¥å…·é€‰æ‹©åˆ¤æ–­ï¼šæ ¹æ®confidenceé€‰æ‹©åˆ†æ”¯
						confidence = flow_state.get('judge_confidence', 0.0)
						if confidence > 0.7 and len(nexts) > 0:
							current_id = nexts[0]  # ç¬¬ä¸€ä¸ªåˆ†æ”¯ï¼šé«˜ç½®ä¿¡åº¦å·¥å…·
							logger.info(f"åˆ¤æ–­èŠ‚ç‚¹ {node.id} é€‰æ‹©é«˜ç½®ä¿¡åº¦å·¥å…·åˆ†æ”¯: {current_id}")
						elif len(nexts) > 1:
							current_id = nexts[1]  # ç¬¬äºŒä¸ªåˆ†æ”¯ï¼šä½ç½®ä¿¡åº¦æˆ–å¤‡é€‰å·¥å…·
							logger.info(f"åˆ¤æ–­èŠ‚ç‚¹ {node.id} é€‰æ‹©å¤‡é€‰å·¥å…·åˆ†æ”¯: {current_id}")
						elif len(nexts) > 0:
							current_id = nexts[0]
						else:
							current_id = None
					
					elif judge_type == 'intent_recognition':
						# æ„å›¾è¯†åˆ«åˆ¤æ–­ï¼šæ ¹æ®requires_toolé€‰æ‹©åˆ†æ”¯
						requires_tool = flow_state.get('judge_requires_tool', False)
						if not requires_tool and len(nexts) > 0:
							current_id = nexts[0]  # ç¬¬ä¸€ä¸ªåˆ†æ”¯ï¼šä¸éœ€è¦å·¥å…·
							logger.info(f"åˆ¤æ–­èŠ‚ç‚¹ {node.id} é€‰æ‹©æ— éœ€å·¥å…·åˆ†æ”¯: {current_id}")
						elif len(nexts) > 1:
							current_id = nexts[1]  # ç¬¬äºŒä¸ªåˆ†æ”¯ï¼šéœ€è¦å·¥å…·
							logger.info(f"åˆ¤æ–­èŠ‚ç‚¹ {node.id} é€‰æ‹©éœ€è¦å·¥å…·åˆ†æ”¯: {current_id}")
						elif len(nexts) > 0:
							current_id = nexts[0]
						else:
							current_id = None
					
					else:
						# è‡ªå®šä¹‰åˆ¤æ–­ç±»å‹ï¼šé»˜è®¤èµ°ç¬¬ä¸€ä¸ªåˆ†æ”¯
						if len(nexts) > 0:
							current_id = nexts[0]
							logger.info(f"åˆ¤æ–­èŠ‚ç‚¹ {node.id} ä½¿ç”¨é»˜è®¤åˆ†æ”¯: {current_id}")
						else:
							current_id = None
					
					continue

				if node.type == NodeType.AGENT:
					# è°ƒç”¨ç›®æ ‡æ™ºèƒ½ä½“ï¼ˆéæµå¼ï¼‰ï¼Œæ•´ä½“ä½œä¸ºä¸€æ®µå†…å®¹è¾“å‡º
					agent_resp = await self._execute_agent_node(node, user_id, message, context)
					flow_state['last_output'] = flow_state.get('last_output', '') + (agent_resp.content or '')
					yield StreamChunk(
						chunk_id=str(uuid.uuid4()),
						session_id=(context or {}).get('session_id', ''),
						type="content",
						content=agent_resp.content or '',
						agent_name=self.name,
						metadata={
							'node_id': node.id,
							'node_type': node.type.value,
							'node_name': node.name,
							'node_label': node.config.get('label', node.name),
							'agent_name': agent_name
						}
					)
					nexts = node.connections or []
					current_id = nexts[0] if nexts else None
					continue

				if node.type == NodeType.ROUTER:
					# æ‰§è¡Œè·¯ç”±èŠ‚ç‚¹
					logger.info(f"ğŸš€ è¿›å…¥ROUTERèŠ‚ç‚¹å¤„ç†åˆ†æ”¯: {current_id}")
					logger.info(f"ğŸš€ å³å°†æ‰§è¡Œè·¯ç”±èŠ‚ç‚¹: {node.id} ({node.name})")
					
					router_msg = await self._execute_router_node(node, user_id, message, context)
					flow_state['last_output'] = flow_state.get('last_output', '') + (router_msg.content or '')
					
					# è¾“å‡ºè·¯ç”±å†³ç­–
					yield StreamChunk(
						chunk_id=str(uuid.uuid4()),
						session_id=(context or {}).get('session_id', ''),
						type="content",
						content=router_msg.content or '',
						agent_name=self.name,
						metadata={
							'node_id': node.id,
							'node_type': node.type.value,
							'node_name': node.name,
							'node_label': node.config.get('label', node.name),
							'selected_branch': router_msg.metadata.get('selected_branch')
						}
					)
					
					# æ ¹æ®è·¯ç”±å†³ç­–å†³å®šä¸‹ä¸€æ­¥
					selected_branch = router_msg.metadata.get('selected_branch')
					nexts = node.connections or []
					
					if selected_branch and nexts:
						# æ ¹æ®è·¯ç”±å†³ç­–é€‰æ‹©åˆ†æ”¯
						if selected_branch == 'true' and len(nexts) > 0:
							current_id = nexts[0]  # ç¬¬ä¸€ä¸ªåˆ†æ”¯ï¼šçœŸå€¼åˆ†æ”¯
							logger.info(f"è·¯ç”±èŠ‚ç‚¹ {node.id} é€‰æ‹©çœŸå€¼åˆ†æ”¯: {current_id}")
						elif selected_branch == 'false' and len(nexts) > 1:
							current_id = nexts[1]  # ç¬¬äºŒä¸ªåˆ†æ”¯ï¼šå‡å€¼åˆ†æ”¯
							logger.info(f"è·¯ç”±èŠ‚ç‚¹ {node.id} é€‰æ‹©å‡å€¼åˆ†æ”¯: {current_id}")
						elif len(nexts) > 0:
							# åªæœ‰ä¸€ä¸ªåˆ†æ”¯ï¼Œç»§ç»­æ‰§è¡Œ
							current_id = nexts[0]
							logger.info(f"è·¯ç”±èŠ‚ç‚¹ {node.id} åªæœ‰ä¸€ä¸ªåˆ†æ”¯ï¼Œç»§ç»­æ‰§è¡Œ: {current_id}")
						else:
							current_id = None
							logger.info(f"è·¯ç”±èŠ‚ç‚¹ {node.id} æ²¡æœ‰åç»­èŠ‚ç‚¹ï¼Œç»“æŸæµç¨‹")
					else:
						# æ²¡æœ‰è·¯ç”±å†³ç­–æˆ–åç»­èŠ‚ç‚¹ï¼Œç»“æŸæµç¨‹
						current_id = None
						logger.info(f"è·¯ç”±èŠ‚ç‚¹ {node.id} æœªæ‰¾åˆ°åˆ†æ”¯ï¼Œç»“æŸæµç¨‹")
					
					continue

				# æœªçŸ¥èŠ‚ç‚¹ï¼Œç»“æŸ
				break

			# æœ€ç»ˆè¾“å‡º
			yield StreamChunk(
				chunk_id=str(uuid.uuid4()),
				session_id=(context or {}).get('session_id', ''),
				type="final",
				content=flow_state.get('last_output', ''),
				agent_name=self.name,
				metadata={},
				is_end=True
			)
		except Exception as e:
			logger.error(f"æµå¼å¤„ç†æ¶ˆæ¯å¤±è´¥: {str(e)}")
			yield StreamChunk(
				chunk_id=str(uuid.uuid4()),
				session_id=(context or {}).get('session_id', ''),
				type="error",
				content=f"å¤„ç†æ¶ˆæ¯æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}",
				agent_name=self.name,
				metadata={'error': str(e)},
				is_end=True
			) 